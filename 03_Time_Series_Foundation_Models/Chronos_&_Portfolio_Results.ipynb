{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl3cjoU9BjrX"
      },
      "source": [
        "# **01. Import Libraries and Load Data**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTheBB-Bqpd0",
        "outputId": "fba1598b-f2b4-47f3-b2dc-c41240b4ee6f"
      },
      "outputs": [],
      "source": [
        "pip install wrds --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI5fhCBl4-ab"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wrds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqgDuMzerBMD"
      },
      "source": [
        "## Connect to WRDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtZdFaD2wkDH",
        "outputId": "ee25713c-af1a-4a75-f381-1ebb15f02839"
      },
      "outputs": [],
      "source": [
        "# Establish a connection to the WRDS\n",
        "db = wrds.Connection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ph1EzpeJJiV"
      },
      "source": [
        "# **02. Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOuv3x3sLxIJ"
      },
      "source": [
        "## Select 50 Top Stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMDOukbMN0uP"
      },
      "outputs": [],
      "source": [
        "# Get the earliest trading date for each permno\n",
        "query_earliest_date = \"\"\"\n",
        "SELECT\n",
        "    permno,\n",
        "    MIN(date) as first_trade_date\n",
        "FROM\n",
        "    crsp.dsf\n",
        "GROUP BY\n",
        "    permno\n",
        "HAVING\n",
        "    MIN(date) <= '2000-01-01'\n",
        "\"\"\"\n",
        "\n",
        "earliest_dates = db.raw_sql(query_earliest_date)\n",
        "\n",
        "# Ensure stocks are still active until December 31, 2024 (latest available date)\n",
        "query_active_stocks = \"\"\"\n",
        "SELECT\n",
        "    permno\n",
        "FROM\n",
        "    crsp.dsf\n",
        "WHERE\n",
        "    date BETWEEN '2000-01-01' AND '2024-12-31'\n",
        "GROUP BY\n",
        "    permno\n",
        "HAVING\n",
        "    COUNT(DISTINCT date) = (SELECT COUNT(DISTINCT date)\n",
        "                            FROM crsp.dsf\n",
        "                            WHERE date BETWEEN '2000-01-01' AND '2024-12-31')\n",
        "\"\"\"\n",
        "\n",
        "active_stocks = db.raw_sql(query_active_stocks)\n",
        "\n",
        "# Combine the two sets of stocks to get those listed before 2000 and still active in 2024\n",
        "filtered_permnos = earliest_dates.merge(active_stocks, on='permno', how='inner')\n",
        "\n",
        "# Get the list of permnos as a comma-separated string\n",
        "permnos_str = ','.join([str(permno) for permno in filtered_permnos['permno'].tolist()])\n",
        "\n",
        "# Get market capitalisation, company name, and sector information for IT sector\n",
        "query_main = f\"\"\"\n",
        "SELECT\n",
        "    a.permco,\n",
        "    a.permno,\n",
        "    a.date,\n",
        "    a.shrout,\n",
        "    a.prc * a.shrout as market_cap,\n",
        "    b.shrcd,\n",
        "    b.exchcd,\n",
        "    b.siccd,\n",
        "    b.ncusip,\n",
        "    b.comnam\n",
        "FROM\n",
        "    crsp.dsf AS a\n",
        "JOIN\n",
        "    crsp.dsenames AS b\n",
        "ON\n",
        "    a.permno = b.permno\n",
        "WHERE\n",
        "    (\n",
        "        (b.siccd BETWEEN 3570 AND 3579) OR  -- IT-related services (programming, software, etc.)\n",
        "        (b.siccd BETWEEN 3600 AND 3674) OR\n",
        "        (b.siccd BETWEEN 7370 AND 7379) OR\n",
        "        (b.siccd BETWEEN 4810 AND 4813)\n",
        "    )\n",
        "    AND a.permno IN ({permnos_str})\n",
        "    AND a.date = '2024-12-31'\n",
        "    AND b.exchcd IN (1, 3)\n",
        "\"\"\"\n",
        "\n",
        "# Execute query\n",
        "crsp_data = db.raw_sql(query_main)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k73TOTxuVBiB",
        "outputId": "2f6e93e2-5e41-4cd5-fbcb-e6efece93e1f"
      },
      "outputs": [],
      "source": [
        "# Check the results from crsp_data\n",
        "crsp_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WxOmABSjyUs",
        "outputId": "69799ef9-04d4-4e2a-aa0d-5a4034bf819e"
      },
      "outputs": [],
      "source": [
        "print(\"Original dataset size: \", len(crsp_data))\n",
        "print(\"Original number of stocks: \", len(set(crsp_data['permno'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkk21ag-MYPH",
        "outputId": "bce93141-5eeb-4321-a159-6fb1b129c9d2"
      },
      "outputs": [],
      "source": [
        "# Filter data for the latest date\n",
        "latest_date = crsp_data['date'].max()\n",
        "latest_data = crsp_data[crsp_data['date'] == latest_date]\n",
        "\n",
        "# Group by permco and permno and select the entry with the highest market capitalisation within each group\n",
        "top_50_IT_stocks = latest_data.groupby(['permco', 'permno']).apply(lambda x: x.nlargest(1, 'market_cap'))\n",
        "\n",
        "# Sort by market capitalization and get the top 25 stocks\n",
        "top_50_IT_stocks = top_50_IT_stocks.sort_values(by='market_cap', ascending=False).head(50)\n",
        "top_50_IT_stocks.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlfVcnfoMknx",
        "outputId": "3f5c478d-b357-4c43-cd00-cf1e931c41a5"
      },
      "outputs": [],
      "source": [
        "print(top_50_IT_stocks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMI8Vd3vQ5LS",
        "outputId": "2b6b5d12-967a-4117-875a-1b22472de088"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in important columns\n",
        "missing_data = crsp_data[crsp_data[['market_cap', 'comnam', 'ncusip']].isna().any(axis=1)]\n",
        "\n",
        "# Display the rows with missing data\n",
        "print(missing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHf_X0ybkTCz",
        "outputId": "3c86c811-331f-4c76-a6c5-7c33361741aa"
      },
      "outputs": [],
      "source": [
        "# Before removing duplicates\n",
        "print(f\"Data size before removing duplicates: {crsp_data.shape}\")\n",
        "\n",
        "# Remove duplicates\n",
        "crsp_data.drop_duplicates(subset=['permno', 'date', 'date'], keep='first', inplace=True)\n",
        "\n",
        "# After removing duplicates\n",
        "print(f\"Data size after removing duplicates: {crsp_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5YSSrkHsj8z"
      },
      "source": [
        "## Collect Price and Return Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-vvDR2TQK9m"
      },
      "outputs": [],
      "source": [
        "# get permno of the top 50 stocks\n",
        "top_50_permnos = top_50_IT_stocks['permno'].tolist()\n",
        "\n",
        "# convert permno list to a string for the SQL IN clause\n",
        "permnos_str = ', '.join(map(str, top_50_permnos))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJfu8ceddkmV"
      },
      "source": [
        "### Download train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypUhrylXPpaH"
      },
      "outputs": [],
      "source": [
        "# Define the date range\n",
        "start_date = '2000-01-01'\n",
        "end_date = '2015-12-31'\n",
        "\n",
        "# Query to get data for the specified date range and variables for the top 50 stocks\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "    a.permco,\n",
        "    a.permno,\n",
        "    b.comnam,\n",
        "    b.ticker,\n",
        "    a.date,\n",
        "    a.prc,\n",
        "    a.cfacpr,\n",
        "    a.ret\n",
        "FROM\n",
        "    crsp.dsf AS a\n",
        "JOIN\n",
        "    (SELECT permno, comnam, ticker, namedt, nameendt\n",
        "     FROM crsp.dsenames\n",
        "     WHERE permno IN ({permnos_str}) -- filter for the top 50 stocks\n",
        "       AND namedt <= '{end_date}'\n",
        "       AND (nameendt IS NULL OR nameendt >= '{start_date}')) AS b\n",
        "ON\n",
        "    a.permno = b.permno\n",
        "WHERE\n",
        "    a.permno IN ({permnos_str})     -- filter for the top 50 stocks\n",
        "    AND a.date BETWEEN '{start_date}' AND '{end_date}'\n",
        "    AND a.date >= b.namedt\n",
        "    AND (a.date <= b.nameendt OR b.nameendt IS NULL)\n",
        "\"\"\"\n",
        "\n",
        "# Execute query\n",
        "crsp_train = db.raw_sql(query)\n",
        "crsp_train.sort_values(by=['permco', 'date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-SmkYRGSk05",
        "outputId": "51aa5e25-1e39-4e50-bf7f-a91befff113b"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(crsp_train.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNu2PQioW6xX"
      },
      "outputs": [],
      "source": [
        "# Drop rows where 'prc' or 'ret' are missing (NaN)\n",
        "crsp_train = crsp_train.dropna(subset=['prc', 'ret'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K_ntcqTgSMe",
        "outputId": "d2aa1263-be2c-46f5-c270-0827cfe45f97"
      },
      "outputs": [],
      "source": [
        "crsp_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYbmPvkS1kbz"
      },
      "source": [
        "## Merge the Risk-Free Rate with Stock Returns (Calculate Excess Returns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4yuJmrzE_x1",
        "outputId": "ecb8adba-9566-4eba-85ff-9350c727e258"
      },
      "outputs": [],
      "source": [
        "# Query to fetch the daily risk-free rate for the period 2000-2015\n",
        "query_risk_free = \"\"\"\n",
        "SELECT\n",
        "    date,\n",
        "    rf\n",
        "FROM\n",
        "    ff.factors_daily\n",
        "WHERE\n",
        "    date BETWEEN '2000-01-01' AND '2015-12-31'\n",
        "\"\"\"\n",
        "rf_data = db.raw_sql(query_risk_free)\n",
        "\n",
        "# Ensure both 'date' columns are in datetime format before merging\n",
        "crsp_train['date'] = pd.to_datetime(crsp_train['date'], errors='coerce')\n",
        "rf_data['date'] = pd.to_datetime(rf_data['date'], errors='coerce')\n",
        "\n",
        "# Merge the risk-free rate with stock data\n",
        "crsp_train = pd.merge(crsp_train, rf_data, how='left', on='date')\n",
        "\n",
        "# Adjust the returns by factoring in the price adjustment factor (cfacpr)\n",
        "crsp_train['adjusted_ret'] = crsp_train['ret'] / crsp_train['cfacpr']\n",
        "\n",
        "# Calculate excess returns using the adjusted returns\n",
        "crsp_train['excess_ret'] = crsp_train['adjusted_ret'] - crsp_train['rf']\n",
        "\n",
        "# Clip abnormal returns to +100% and -100%\n",
        "crsp_train['excess_ret'] = crsp_train['excess_ret'].clip(lower=-1.0, upper=1.0)\n",
        "\n",
        "# Convert the excess return to a binary target for directional forecasting\n",
        "crsp_train['directional_target'] = np.where(crsp_train['excess_ret'] > 0, 1, 0)\n",
        "\n",
        "# Check the results for train data\n",
        "crsp_train[['permco', 'permno', 'date', 'adjusted_ret', 'excess_ret']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uecdeumUFoBt"
      },
      "source": [
        "### Download test data (2016-2024)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA-6blOlFAlu"
      },
      "outputs": [],
      "source": [
        "# Define the date range\n",
        "start_date = '2016-01-01'\n",
        "end_date = '2024-12-31'\n",
        "\n",
        "# Query to get data for the specified date range and variables for the top 50 stocks\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "    a.permco,\n",
        "    a.permno,\n",
        "    b.comnam,\n",
        "    b.ticker,\n",
        "    a.date,\n",
        "    a.prc,\n",
        "    a.cfacpr,\n",
        "    a.ret\n",
        "FROM\n",
        "    crsp.dsf AS a\n",
        "JOIN\n",
        "    (SELECT permno, comnam, ticker, namedt, nameendt\n",
        "     FROM crsp.dsenames\n",
        "     WHERE permno IN ({permnos_str}) -- filter for the top 50 stocks\n",
        "       AND namedt <= '{end_date}'\n",
        "       AND (nameendt IS NULL OR nameendt >= '{start_date}')) AS b\n",
        "ON\n",
        "    a.permno = b.permno\n",
        "WHERE\n",
        "    a.permno IN ({permnos_str})       -- filter for the top 50 stocks\n",
        "    AND a.date BETWEEN '{start_date}' AND '{end_date}'\n",
        "    AND a.date >= b.namedt\n",
        "    AND (a.date <= b.nameendt OR b.nameendt IS NULL)\n",
        "\"\"\"\n",
        "# Execute query\n",
        "crsp_test = db.raw_sql(query)\n",
        "crsp_test.sort_values(by=['permco', 'date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfWmLFhGUHEx",
        "outputId": "20af2db1-b58f-4adb-b599-c1270d18606e"
      },
      "outputs": [],
      "source": [
        "crsp_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYyrO8_33AyO",
        "outputId": "56970c52-1063-4d51-95c7-98d31bc09e08"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(crsp_test.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km8AIbFrnBS8"
      },
      "source": [
        "### Calculate Excess Returns for Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wdXWmdQnAcr",
        "outputId": "1ade889d-252f-4934-e1c6-38d3d86b2bd4"
      },
      "outputs": [],
      "source": [
        "# Use the Fama French data to get the daily risk-free rate for the test period (2016-2024)\n",
        "query_risk_free_test = \"\"\"\n",
        "SELECT\n",
        "    date,\n",
        "    rf\n",
        "FROM\n",
        "    ff.factors_daily\n",
        "WHERE\n",
        "    date BETWEEN '2016-01-01' AND '2024-12-31'\n",
        "\"\"\"\n",
        "rf_data_test = db.raw_sql(query_risk_free_test)\n",
        "\n",
        "# Merge risk-free rate with test data\n",
        "crsp_test['date'] = pd.to_datetime(crsp_test['date'], errors='coerce')\n",
        "rf_data_test['date'] = pd.to_datetime(rf_data_test['date'], errors='coerce')\n",
        "\n",
        "# Merge the test data with the risk-free rate data\n",
        "crsp_test = pd.merge(crsp_test, rf_data_test, how='left', on='date')\n",
        "\n",
        "# Adjust the returns by factoring in the price adjustment factor (cfacpr)\n",
        "crsp_test['adjusted_ret'] = crsp_test['ret'] / crsp_test['cfacpr']\n",
        "\n",
        "# Calculate excess returns using the adjusted returns\n",
        "crsp_test['excess_ret'] = crsp_test['adjusted_ret'] - crsp_test['rf']\n",
        "\n",
        "# Clip abnormal returns to +100% and -100%\n",
        "crsp_test['excess_ret'] = crsp_test['excess_ret'].clip(lower=-1.0, upper=1.0)\n",
        "\n",
        "# Convert the excess return to a binary target for directional forecasting\n",
        "crsp_test['directional_target'] = np.where(crsp_test['excess_ret'] > 0, 1, 0)\n",
        "\n",
        "# Check the results for test data\n",
        "crsp_test[['permco', 'permno', 'date', 'adjusted_ret', 'excess_ret']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEcnZmbkpE_T"
      },
      "source": [
        "This is because the risk-free rate (rf) is very close to zero around those years."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcOzD8ynMhaA"
      },
      "source": [
        "## Descriptive Statistics for Excess Returns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cauk1tPXKOtX",
        "outputId": "3c5312c5-6a7d-4b7f-e15c-953e99aa5286"
      },
      "outputs": [],
      "source": [
        "# Calculate descriptive statistics for excess returns in the training dataset\n",
        "in_sample_stats = crsp_train[\"excess_ret\"].describe()\n",
        "\n",
        "# Print the statistics in the desired format\n",
        "print(\"In-Sample Excess Return Stats:\")\n",
        "print(in_sample_stats)\n",
        "\n",
        "# Display the dtype\n",
        "print(f\"Name: excess_ret, dtype: {crsp_train['excess_ret'].dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQWsArAJKxRx",
        "outputId": "37900d34-b5ba-4831-f65e-e0ff7c30ad7f"
      },
      "outputs": [],
      "source": [
        "# Calculate descriptive statistics for excess returns in the testing dataset\n",
        "out_sample_stats = crsp_test[\"excess_ret\"].describe()\n",
        "\n",
        "# Print the statistics in the desired format\n",
        "print(\"Out-Sample Excess Return Stats:\")\n",
        "print(out_sample_stats)\n",
        "\n",
        "# Display the dtype\n",
        "print(f\"Name: excess_ret, dtype: {crsp_test['excess_ret'].dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuvJLW92MgQy",
        "outputId": "9202cee5-4758-4822-d059-f342c885dc0d"
      },
      "outputs": [],
      "source": [
        "train_stats = crsp_train.groupby('permno')['excess_ret'].describe()\n",
        "test_stats = crsp_test.groupby('permno')['excess_ret'].describe()\n",
        "\n",
        "# Print descriptive statistics\n",
        "print(\"Descriptive Statistics for Excess Returns (Training Period):\")\n",
        "print(train_stats)\n",
        "\n",
        "print(\"\\nDescriptive Statistics for Excess Returns (Test Period):\")\n",
        "print(test_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k19gsrJPAZZu"
      },
      "source": [
        "## Create Rolling Windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpbEEU6ScDn3",
        "outputId": "82fa0476-bcac-4ff6-c3d8-6ef79fcedbf2"
      },
      "outputs": [],
      "source": [
        "def create_lag_features(df, lags):\n",
        "    # Sort the data by stock ID ('permno') and date to ensure correct time order\n",
        "    df_sorted = df.sort_values(by=[\"permno\", \"date\"])\n",
        "\n",
        "    # Loop through each lag value provided (e.g., 5, 21, 252, 512)\n",
        "    for lag in lags:\n",
        "        # Create lag features by shifting excess returns and applying a rolling window\n",
        "        df[f\"lag_{lag}\"] = (\n",
        "            df_sorted.groupby(\"permno\")[\"excess_ret\"]  # Group by stock\n",
        "            .shift(1)  # Shift by 1 day to avoid lookahead bias\n",
        "            .rolling(window=lag, min_periods=1)  # Rolling window over past 'lag' days\n",
        "            .mean()  # Calculate the mean of the rolling window\n",
        "        )\n",
        "\n",
        "    # Return the DataFrame with added lag features\n",
        "    return df\n",
        "\n",
        "# Example usage for both crsp_train and crsp_test\n",
        "lag_days_list = [5, 21, 252, 512]  # Example list of lag days\n",
        "\n",
        "# Apply the function to both crsp_train and crsp_test\n",
        "crsp_train_lagged = create_lag_features(crsp_train, lag_days_list)\n",
        "crsp_test_lagged = create_lag_features(crsp_test, lag_days_list)\n",
        "\n",
        "# Drop rows where any of the lag columns are NaN in crsp_test_lagged\n",
        "crsp_test_lagged = crsp_test_lagged.dropna(subset=[f'lag_{lag}' for lag in lag_days_list])\n",
        "\n",
        "# Verify that the lag features are correctly added\n",
        "print(crsp_train_lagged.head())\n",
        "print(crsp_test_lagged.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a4pJND_8IPp"
      },
      "source": [
        "# **03. Merge**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev1IOEiA8KLl"
      },
      "outputs": [],
      "source": [
        "# Merge crsp_data and crsp_test_lagged on the stock ID (permno)\n",
        "merged_df = crsp_test_lagged.merge(crsp_data[['permno', 'market_cap']], on='permno', how='left')\n",
        "\n",
        "# Step 1: Rename 'market_cap' in merged_df to avoid conflict during merge\n",
        "merged_df = merged_df.rename(columns={'market_cap': 'market_cap_merged'})\n",
        "\n",
        "# Step 2: Merge 'market_cap' (now renamed to 'market_cap_merged') from merged_df into crsp_test_lagged based on 'permco' and 'date'\n",
        "crsp_test_lagged = crsp_test_lagged.merge(merged_df[['permco', 'date', 'market_cap_merged']], how='left', on=['permco', 'date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5uP2xDdQpVt"
      },
      "source": [
        "# **04. Chronos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIZ6OcYMcr-J",
        "outputId": "c2b5a960-8050-4463-e75b-b559ac2bb5b5"
      },
      "outputs": [],
      "source": [
        "!pip install chronos-forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krG1e5BCbfHq",
        "outputId": "c5c784f4-5e8b-43f0-d212-4afb71e8bc87"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/amazon-science/chronos-forecasting.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k6ez84lcg3x",
        "outputId": "efc24c1d-e57a-461f-c9cf-bec32312cb9b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn2EhIU4vWrC",
        "outputId": "3be0c07e-4e40-41ce-cd59-6b36b988438d"
      },
      "outputs": [],
      "source": [
        "from chronos import ChronosPipeline, ChronosBoltPipeline\n",
        "\n",
        "print(ChronosPipeline.predict.__doc__)  # for Chronos models\n",
        "print(ChronosBoltPipeline.predict.__doc__)  # for Chronos-Bolt models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwn6SU5BIt6y",
        "outputId": "aa6e67c8-2941-405b-e314-d1f0f19a7a71"
      },
      "outputs": [],
      "source": [
        "!pip install datasetsforecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSm0hFtsIpGs",
        "outputId": "c853d315-60b1-42c7-a2db-3c7b6b2697f2"
      },
      "outputs": [],
      "source": [
        "import datasetsforecast\n",
        "print(dir(datasetsforecast))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4pvEtzHD9vF",
        "outputId": "fc8965f8-465a-4d71-d380-143bf65ae0ff"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datasetsforecast.m3 import M3\n",
        "from utilsforecast.losses import *\n",
        "from utilsforecast.evaluation import evaluate\n",
        "import torch\n",
        "from chronos import ChronosPipeline\n",
        "\n",
        "Y_df, *_ = M3.load(directory='./', group='Monthly')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCIAF9G7LtSj"
      },
      "outputs": [],
      "source": [
        "from chronos import BaseChronosPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAJ2GvzHdNJU"
      },
      "source": [
        "## Chronos-T5 Tiny (8M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3so1Hkm_bQK3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tqdm import tqdm\n",
        "from chronos import ChronosPipeline\n",
        "\n",
        "def run_forecast_chronos_t5_tiny(crsp_train_lagged, crsp_test_lagged, lag, out_sample_start):\n",
        "    lag_days_list = [5, 21, 252, 512]\n",
        "    if lag not in lag_days_list:\n",
        "        raise ValueError(f\"Invalid lag. Please choose from {lag_days_list}.\")\n",
        "\n",
        "    all_results = []\n",
        "    all_predictions = []\n",
        "    df_test = crsp_test_lagged[crsp_test_lagged[\"date\"] >= out_sample_start].copy()\n",
        "\n",
        "    # Initialize lists\n",
        "    contexts, targets, records = [], [], []\n",
        "\n",
        "    for permno, grp in df_test.groupby(\"permno\"):\n",
        "        values = grp[\"excess_ret\"].values\n",
        "        dates = grp[\"date\"].values\n",
        "\n",
        "        # Efficient tensor creation\n",
        "        for i in range(len(values) - lag):\n",
        "            context = values[i:i + lag]\n",
        "            target = values[i + lag]\n",
        "            contexts.append(context)\n",
        "            targets.append(target)\n",
        "            records.append({\n",
        "                \"permno\": permno,\n",
        "                \"date\": dates[i + lag]\n",
        "            })\n",
        "\n",
        "    # Convert contexts to tensor directly\n",
        "    contexts = torch.tensor(contexts, dtype=torch.float32)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    model_name = \"amazon/chronos-t5-tiny\"\n",
        "    pipeline = ChronosPipeline.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"cpu\",\n",
        "        torch_dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # Use zero-shot forecasting with quantile prediction\n",
        "    preds = []\n",
        "\n",
        "    for ctx in tqdm(contexts, desc=f\"Processing {model_name} with lag={lag}\"):\n",
        "        quantiles, mean = pipeline.predict_quantiles(context=[ctx], prediction_length=1, quantile_levels=[0.5])\n",
        "        preds.append(mean.cpu().squeeze().item())  # Extract the mean value from the quantiles\n",
        "\n",
        "    results = pd.DataFrame(records)\n",
        "    results[\"y_true\"] = targets\n",
        "    results[\"y_pred\"] = preds\n",
        "\n",
        "    y_test = results[\"y_true\"]\n",
        "    y_pred = results[\"y_pred\"]\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    acc = (np.sign(y_test) == np.sign(y_pred)).mean()\n",
        "    up_mask = y_test > 0\n",
        "    down_mask = y_test < 0\n",
        "    acc_up = (np.sign(y_pred[up_mask]) == 1).mean() if up_mask.sum() > 0 else np.nan\n",
        "    acc_down = (np.sign(y_pred[down_mask]) == -1).mean() if down_mask.sum() > 0 else np.nan\n",
        "\n",
        "    result = pd.DataFrame([{\n",
        "        'Model': model_name,\n",
        "        'Lag': lag,\n",
        "        'R2': r2,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'Directional_Accuracy': acc,\n",
        "        'Upward_Accuracy': acc_up,\n",
        "        'Downward_Accuracy': acc_down\n",
        "    }])\n",
        "\n",
        "    result.to_csv(f\"chronost5tiny_results_lag{lag}.csv\", index=False)\n",
        "    results.to_csv(f\"chronost5tiny_results_lag{lag}_full.csv\", index=False)\n",
        "\n",
        "    all_results.append(result)\n",
        "    all_predictions.append(results)\n",
        "\n",
        "    final_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "    if all_predictions:\n",
        "        combined_preds = pd.concat(all_predictions, ignore_index=True)\n",
        "        crsp_test_lagged = crsp_test_lagged.merge(\n",
        "            combined_preds[['permno', 'date', 'y_pred']],\n",
        "            on=['permno', 'date'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Rename the merged 'y_pred' column to the desired lag-specific name\n",
        "        crsp_test_lagged.rename(columns={'y_pred': f'predicted_excess_returns_lag{lag}'}, inplace=True)\n",
        "\n",
        "    else:\n",
        "        crsp_test_lagged[f'predicted_excess_returns_lag{lag}'] = np.nan\n",
        "\n",
        "    return final_df, crsp_test_lagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "FSdPuwysuEag",
        "outputId": "00d6ed41-59b9-412c-ea9c-722dbb86ccb4"
      },
      "outputs": [],
      "source": [
        "# Lag 5\n",
        "lag = 5\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronost5tiny5 = run_forecast_chronos_t5_tiny(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronost5tiny5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "hxMU-2NZhaZY",
        "outputId": "ecef5500-94fe-45f1-c44b-705d6e8f2a20"
      },
      "outputs": [],
      "source": [
        "# Lag 21\n",
        "lag = 21\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronost5tiny21 = run_forecast_chronos_t5_tiny(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronost5tiny21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "eTWD1oDjiDQm",
        "outputId": "83d64349-9ad1-46fa-ddd2-901513614bc8"
      },
      "outputs": [],
      "source": [
        "# Lag 252\n",
        "lag = 252\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronost5tiny252 = run_forecast_chronos_t5_tiny(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronost5tiny252)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "28fc4f83515d4256862128cc9976e17f",
            "8436d83ebc3f4821b82b9b6555a10f63",
            "bc8c2b8253cd45a28e49ad66b60fdd77",
            "82ad82b8ac134452a65033ad758a53ed",
            "eb570852d59d49c5b639350a2bf5d2cb",
            "d92ce63902444f2f816c3efa8a7ac2af",
            "4bcffd06f5f144969ad0f8ace650419c",
            "8b053fceab50414ab645746dd59aa09e",
            "416b8185f9c848e699c0466a05a2926b",
            "5248ec40691f46a88a8d0267db51435d",
            "0957cc0a234b4d5ba085c016a5d6f15a",
            "d32e084f3b664c788502d970fb446e63",
            "98f12bc2038b49feacee02bdd6af84be",
            "382cd0d3d5944c6495cb5fba0bb3dbee",
            "1b7fdf465c484430a7ec57039e70374d",
            "d2778d3c30ca4bb98a0997c8d376be20",
            "08b0c8fd83ab42899a0111fd67d0bc94",
            "fa0c1a027730422d961591044efb3ab9",
            "33d314491ffa43239bc9c9dfa47e3419",
            "c9976eb7c8a64fc6b70822ddf96d83a0",
            "2b6251b1fa7646989886370120bae09b",
            "3b28cc4384ee4a2e8393b7fb8b65972b",
            "675ef567a07e498c9837bc4c5a92dc5c",
            "3f638a8821564890b3a7061d467b4d82",
            "789c14c4ca4546d182e3e8a0ee2d9373",
            "94855e0e08b94d448dd174238f1c8b94",
            "d435e10d772f4f50a8b405f1999c4cad",
            "bc6a0000be7a4589a8ee36d5c8f88ff3",
            "e4a0b96acde14442a580274378f6fcb6",
            "ced2f3a3b306422f856b18b6ece2abf9",
            "89e265d4cd3f43ba9f476bc73063fefd",
            "0d11275d2aa0471ea27b8f5df6c7bedc",
            "494fc22b14dc4282a17cbd481e9ecdaf"
          ]
        },
        "id": "XR3bM6ebiGbW",
        "outputId": "49c40d98-f61d-45d6-8e0f-bcc745a9e60f"
      },
      "outputs": [],
      "source": [
        "# Lag 512\n",
        "lag = 512\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronost5tiny512 = run_forecast_chronos_t5_tiny(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronost5tiny512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ0jJeduqKbK"
      },
      "source": [
        "## Chronos-T5 Tiny Portfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQl0wFWLs3Mk"
      },
      "source": [
        "### Window Size 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "Cn45Xuv8qbEk",
        "outputId": "9b1b9672-62d4-4de2-ba27-16776bc02409"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `Chronos T5 Tiny` to predict excess returns\n",
        "def chronost5tiny_5_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[5]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to run_forecast_chronost5tiny\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_t5_tiny(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronost5tiny_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using ChronosT5 Tiny model\n",
        "crsp_test_lagged = chronost5tiny_5_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronost5tiny5  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_5_with_cost': [],\n",
        "    'cum_ES_return_5_with_cost': [],\n",
        "    'cum_ELS_return_5_with_cost': [],\n",
        "    'cum_VL_return_5_with_cost': [],\n",
        "    'cum_VS_return_5_with_cost': [],\n",
        "    'cum_VLS_return_5_with_cost': [],\n",
        "    'cum_EL_return_5_without_cost': [],\n",
        "    'cum_ES_return_5_without_cost': [],\n",
        "    'cum_ELS_return_5_without_cost': [],\n",
        "    'cum_VL_return_5_without_cost': [],\n",
        "    'cum_VS_return_5_without_cost': [],\n",
        "    'cum_VLS_return_5_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 5\n",
        "cum_EL_return_5_with_cost = 0\n",
        "cum_ES_return_5_with_cost = 0\n",
        "cum_ELS_return_5_with_cost = 0\n",
        "cum_VL_return_5_with_cost = 0\n",
        "cum_VS_return_5_with_cost = 0\n",
        "cum_VLS_return_5_with_cost = 0\n",
        "\n",
        "cum_EL_return_5_without_cost = 0\n",
        "cum_ES_return_5_without_cost = 0\n",
        "cum_ELS_return_5_without_cost = 0\n",
        "cum_VL_return_5_without_cost = 0\n",
        "cum_VS_return_5_without_cost = 0\n",
        "cum_VLS_return_5_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 5 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 5 (or any other lag if needed)\n",
        "    returns = compute_returns(group, f'chronost5tiny_{5}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 5\n",
        "    cum_EL_return_5_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_5_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_5_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_5_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_5_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_5_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_5_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_5_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_5_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_5_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_5_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_5_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 5 portfolios\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_EL_return_5_with_cost'].append(cum_EL_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_ES_return_5_with_cost'].append(cum_ES_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_ELS_return_5_with_cost'].append(cum_ELS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_VL_return_5_with_cost'].append(cum_VL_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_VS_return_5_with_cost'].append(cum_VS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_VLS_return_5_with_cost'].append(cum_VLS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_EL_return_5_without_cost'].append(cum_EL_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_ES_return_5_without_cost'].append(cum_ES_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_ELS_return_5_without_cost'].append(cum_ELS_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_VL_return_5_without_cost'].append(cum_VL_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_VS_return_5_without_cost'].append(cum_VS_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny5['cum_VLS_return_5_without_cost'].append(cum_VLS_return_5_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 5\n",
        "cumulative_log_returns_chronost5tiny_lag_5 = pd.DataFrame(cumulative_log_returns_by_date_chronost5tiny5)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 5\n",
        "display(cumulative_log_returns_chronost5tiny_lag_5.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronost5tiny_lag_5.to_csv(\"cumulative_log_chronost5tiny_lag_5.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "jFHie1eZsi--",
        "outputId": "f64384f0-0ae5-454f-d4b0-e49b03f0205c"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_5_with_cost', 'cum_ES_return_5_with_cost', 'cum_ELS_return_5_with_cost',\n",
        "    'cum_VL_return_5_with_cost', 'cum_VS_return_5_with_cost', 'cum_VLS_return_5_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronost5tiny5_c = cumulative_log_returns_chronost5tiny_lag_5[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronost5tiny5_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronost5tiny5_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronost5tiny5_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_5_without_cost', 'cum_ES_return_5_without_cost', 'cum_ELS_return_5_without_cost',\n",
        "    'cum_VL_return_5_without_cost', 'cum_VS_return_5_without_cost', 'cum_VLS_return_5_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronost5tiny5_wc = cumulative_log_returns_chronost5tiny_lag_5[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronost5tiny5_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronost5tiny5_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronost5tiny5_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronost5tiny5_c.to_csv('metrics_chronost5tiny5_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronost5tiny5_wc.to_csv('metrics_chronost5tiny5_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwOhimF3s6R9"
      },
      "source": [
        "### Window Size 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "qGk7JA7hs69q",
        "outputId": "5c7a7736-e1fe-4508-ab41-6065ec6b1f78"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `Chronos T5 Tiny` to predict excess returns\n",
        "def chronost5tiny_21_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[21]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to run_forecast_chronost5tiny\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_t5_tiny(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronost5tiny_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using ChronosT5 Tiny model\n",
        "crsp_test_lagged = chronost5tiny_21_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = (np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative - top_negative['transaction_cost'].mean()\n",
        "    value_short_log_return_without_cost = (np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronost5tiny21  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_21_with_cost': [],\n",
        "    'cum_ES_return_21_with_cost': [],\n",
        "    'cum_ELS_return_21_with_cost': [],\n",
        "    'cum_VL_return_21_with_cost': [],\n",
        "    'cum_VS_return_21_with_cost': [],\n",
        "    'cum_VLS_return_21_with_cost': [],\n",
        "    'cum_EL_return_21_without_cost': [],\n",
        "    'cum_ES_return_21_without_cost': [],\n",
        "    'cum_ELS_return_21_without_cost': [],\n",
        "    'cum_VL_return_21_without_cost': [],\n",
        "    'cum_VS_return_21_without_cost': [],\n",
        "    'cum_VLS_return_21_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 21\n",
        "cum_EL_return_21_with_cost = 0\n",
        "cum_ES_return_21_with_cost = 0\n",
        "cum_ELS_return_21_with_cost = 0\n",
        "cum_VL_return_21_with_cost = 0\n",
        "cum_VS_return_21_with_cost = 0\n",
        "cum_VLS_return_21_with_cost = 0\n",
        "\n",
        "cum_EL_return_21_without_cost = 0\n",
        "cum_ES_return_21_without_cost = 0\n",
        "cum_ELS_return_21_without_cost = 0\n",
        "cum_VL_return_21_without_cost = 0\n",
        "cum_VS_return_21_without_cost = 0\n",
        "cum_VLS_return_21_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 21 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 21 (or any other lag if needed)\n",
        "    returns = compute_returns(group, f'chronost5tiny_{21}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 21\n",
        "    cum_EL_return_21_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_21_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_21_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_21_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_21_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_21_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_21_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_21_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_21_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_21_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_21_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_21_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 21 portfolios\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_EL_return_21_with_cost'].append(cum_EL_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_ES_return_21_with_cost'].append(cum_ES_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_ELS_return_21_with_cost'].append(cum_ELS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_VL_return_21_with_cost'].append(cum_VL_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_VS_return_21_with_cost'].append(cum_VS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_VLS_return_21_with_cost'].append(cum_VLS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_EL_return_21_without_cost'].append(cum_EL_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_ES_return_21_without_cost'].append(cum_ES_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_ELS_return_21_without_cost'].append(cum_ELS_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_VL_return_21_without_cost'].append(cum_VL_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_VS_return_21_without_cost'].append(cum_VS_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny21['cum_VLS_return_21_without_cost'].append(cum_VLS_return_21_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 21\n",
        "cumulative_log_returns_chronost5tiny_lag_21 = pd.DataFrame(cumulative_log_returns_by_date_chronost5tiny21)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 21\n",
        "display(cumulative_log_returns_chronost5tiny_lag_21.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronost5tiny_lag_21.to_csv(\"cumulative_log_chronost5tiny_lag_21.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "JlW_gH-1tm8j",
        "outputId": "13022de9-5b2c-4255-c087-750632340205"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_21_with_cost', 'cum_ES_return_21_with_cost', 'cum_ELS_return_21_with_cost',\n",
        "    'cum_VL_return_21_with_cost', 'cum_VS_return_21_with_cost', 'cum_VLS_return_21_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronost5tiny21_c = cumulative_log_returns_chronost5tiny_lag_21[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronost5tiny21_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)  # Using percentage-based cost for volatility\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronost5tiny21_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronost5tiny21_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_21_without_cost', 'cum_ES_return_21_without_cost', 'cum_ELS_return_21_without_cost',\n",
        "    'cum_VL_return_21_without_cost', 'cum_VS_return_21_without_cost', 'cum_VLS_return_21_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronost5tiny21_wc = cumulative_log_returns_chronost5tiny_lag_21[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronost5tiny21_wc)\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronost5tiny21_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronost5tiny21_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronost5tiny21_c.to_csv('metrics_chronost5tiny21_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronost5tiny21_wc.to_csv('metrics_chronost5tiny21_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH1JIOxyt8cg"
      },
      "source": [
        "### Window Size 252"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574,
          "referenced_widgets": [
            "64beb1e2f1ab4058bd34b6734ff1c7b1",
            "c5e17b9dfcb7497d94cb02e48a431b25",
            "36e5f93b114a46f2950cfdf697dab6f5"
          ]
        },
        "id": "V11WJrXVt9mZ",
        "outputId": "a247154f-a6a6-4b55-93d2-7bd1b9ec4d43"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `Chronos T5 Tiny` to predict excess returns\n",
        "def chronost5tiny_252_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[252]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to run_forecast_chronost5tiny\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_t5_tiny(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronost5tiny_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using ChronosT5 Tiny model\n",
        "crsp_test_lagged = chronost5tiny_252_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronost5tiny252  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_252_with_cost': [],\n",
        "    'cum_ES_return_252_with_cost': [],\n",
        "    'cum_ELS_return_252_with_cost': [],\n",
        "    'cum_VL_return_252_with_cost': [],\n",
        "    'cum_VS_return_252_with_cost': [],\n",
        "    'cum_VLS_return_252_with_cost': [],\n",
        "    'cum_EL_return_252_without_cost': [],\n",
        "    'cum_ES_return_252_without_cost': [],\n",
        "    'cum_ELS_return_252_without_cost': [],\n",
        "    'cum_VL_return_252_without_cost': [],\n",
        "    'cum_VS_return_252_without_cost': [],\n",
        "    'cum_VLS_return_252_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 252\n",
        "cum_EL_return_252_with_cost = 0\n",
        "cum_ES_return_252_with_cost = 0\n",
        "cum_ELS_return_252_with_cost = 0\n",
        "cum_VL_return_252_with_cost = 0\n",
        "cum_VS_return_252_with_cost = 0\n",
        "cum_VLS_return_252_with_cost = 0\n",
        "\n",
        "cum_EL_return_252_without_cost = 0\n",
        "cum_ES_return_252_without_cost = 0\n",
        "cum_ELS_return_252_without_cost = 0\n",
        "cum_VL_return_252_without_cost = 0\n",
        "cum_VS_return_252_without_cost = 0\n",
        "cum_VLS_return_252_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 252 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 252\n",
        "    returns = compute_returns(group, f'chronost5tiny_{252}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 252\n",
        "    cum_EL_return_252_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_252_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_252_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_252_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_252_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_252_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_252_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_252_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_252_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_252_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_252_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_252_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 252 portfolios\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_EL_return_252_with_cost'].append(cum_EL_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_ES_return_252_with_cost'].append(cum_ES_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_ELS_return_252_with_cost'].append(cum_ELS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_VL_return_252_with_cost'].append(cum_VL_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_VS_return_252_with_cost'].append(cum_VS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_VLS_return_252_with_cost'].append(cum_VLS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_EL_return_252_without_cost'].append(cum_EL_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_ES_return_252_without_cost'].append(cum_ES_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_ELS_return_252_without_cost'].append(cum_ELS_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_VL_return_252_without_cost'].append(cum_VL_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_VS_return_252_without_cost'].append(cum_VS_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny252['cum_VLS_return_252_without_cost'].append(cum_VLS_return_252_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 252\n",
        "cumulative_log_returns_chronost5tiny_lag_252 = pd.DataFrame(cumulative_log_returns_by_date_chronost5tiny252)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 252\n",
        "display(cumulative_log_returns_chronost5tiny_lag_252.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronost5tiny_lag_252.to_csv(\"cumulative_log_chronost5tiny_lag_252.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "0lVbNbiFuxuw",
        "outputId": "8d0810ab-b7fa-4bbe-fee9-781831af287c"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_252_with_cost', 'cum_ES_return_252_with_cost', 'cum_ELS_return_252_with_cost',\n",
        "    'cum_VL_return_252_with_cost', 'cum_VS_return_252_with_cost', 'cum_VLS_return_252_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronost5tiny252_c = cumulative_log_returns_chronost5tiny_lag_252[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronost5tiny252_c)\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics (e.g., cumulative returns, Sharpe ratio)\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronost5tiny252_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronost5tiny252_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_252_without_cost', 'cum_ES_return_252_without_cost', 'cum_ELS_return_252_without_cost',\n",
        "    'cum_VL_return_252_without_cost', 'cum_VS_return_252_without_cost', 'cum_VLS_return_252_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronost5tiny252_wc = cumulative_log_returns_chronost5tiny_lag_252[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronost5tiny252_wc)\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronost5tiny252_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronost5tiny252_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronost5tiny252_c.to_csv('metrics_chronost5tiny252_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronost5tiny252_wc.to_csv('metrics_chronost5tiny252_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm2DIN1cvBrA"
      },
      "source": [
        "### Window Size 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "ce224cf0171a4be6b481d6361e988657",
            "1a59c420b0094ba4bfce3d03e0bd9eed",
            "1d8e6fa7a6a54070a079cf7ecdfe3d28"
          ]
        },
        "id": "GuvAbEwy5DYO",
        "outputId": "42a6d857-34ff-48de-a7ed-3d4c9a5c5cff"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `Chronos T5 Tiny` to predict excess returns\n",
        "def chronost5tiny_512_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[512]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to run_forecast_chronost5tiny\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_t5_tiny(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronost5tiny_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using ChronosT5 Tiny model\n",
        "crsp_test_lagged = chronost5tiny_512_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronost5tiny512  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_512_with_cost': [],\n",
        "    'cum_ES_return_512_with_cost': [],\n",
        "    'cum_ELS_return_512_with_cost': [],\n",
        "    'cum_VL_return_512_with_cost': [],\n",
        "    'cum_VS_return_512_with_cost': [],\n",
        "    'cum_VLS_return_512_with_cost': [],\n",
        "    'cum_EL_return_512_without_cost': [],\n",
        "    'cum_ES_return_512_without_cost': [],\n",
        "    'cum_ELS_return_512_without_cost': [],\n",
        "    'cum_VL_return_512_without_cost': [],\n",
        "    'cum_VS_return_512_without_cost': [],\n",
        "    'cum_VLS_return_512_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 512\n",
        "cum_EL_return_512_with_cost = 0\n",
        "cum_ES_return_512_with_cost = 0\n",
        "cum_ELS_return_512_with_cost = 0\n",
        "cum_VL_return_512_with_cost = 0\n",
        "cum_VS_return_512_with_cost = 0\n",
        "cum_VLS_return_512_with_cost = 0\n",
        "\n",
        "cum_EL_return_512_without_cost = 0\n",
        "cum_ES_return_512_without_cost = 0\n",
        "cum_ELS_return_512_without_cost = 0\n",
        "cum_VL_return_512_without_cost = 0\n",
        "cum_VS_return_512_without_cost = 0\n",
        "cum_VLS_return_512_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 512 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 512\n",
        "    returns = compute_returns(group, f'chronost5tiny_{512}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 512\n",
        "    cum_EL_return_512_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_512_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_512_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_512_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_512_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_512_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_512_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_512_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_512_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_512_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_512_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_512_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 512 portfolios\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_EL_return_512_with_cost'].append(cum_EL_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_ES_return_512_with_cost'].append(cum_ES_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_ELS_return_512_with_cost'].append(cum_ELS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_VL_return_512_with_cost'].append(cum_VL_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_VS_return_512_with_cost'].append(cum_VS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_VLS_return_512_with_cost'].append(cum_VLS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_EL_return_512_without_cost'].append(cum_EL_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_ES_return_512_without_cost'].append(cum_ES_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_ELS_return_512_without_cost'].append(cum_ELS_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_VL_return_512_without_cost'].append(cum_VL_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_VS_return_512_without_cost'].append(cum_VS_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronost5tiny512['cum_VLS_return_512_without_cost'].append(cum_VLS_return_512_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 512\n",
        "cumulative_log_returns_chronost5tiny_lag_512 = pd.DataFrame(cumulative_log_returns_by_date_chronost5tiny512)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 512\n",
        "display(cumulative_log_returns_chronost5tiny_lag_512.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronost5tiny_lag_512.to_csv(\"cumulative_log_chronost5tiny_lag_512.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "3HoaJNjP6vbl",
        "outputId": "f8f1f18c-da07-4729-e5ba-d4f8b8558322"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns (for other metrics)\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns (for volatility and standard deviation)\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_512_with_cost', 'cum_ES_return_512_with_cost', 'cum_ELS_return_512_with_cost',\n",
        "    'cum_VL_return_512_with_cost', 'cum_VS_return_512_with_cost', 'cum_VLS_return_512_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronost5tiny512_c = cumulative_log_returns_chronost5tiny_lag_512[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronost5tiny512_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronost5tiny512_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronost5tiny512_c)\n",
        "\n",
        "\n",
        "# Now, the same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_512_without_cost', 'cum_ES_return_512_without_cost', 'cum_ELS_return_512_without_cost',\n",
        "    'cum_VL_return_512_without_cost', 'cum_VS_return_512_without_cost', 'cum_VLS_return_512_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronost5tiny512_wc = cumulative_log_returns_chronost5tiny_lag_512[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronost5tiny512_wc)\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronost5tiny512_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronost5tiny512_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronost5tiny512_c.to_csv('metrics_chronost5tiny512_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronost5tiny512_wc.to_csv('metrics_chronost5tiny512_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdsHzFg_g3i0"
      },
      "source": [
        "## Chronos_bolt Tiny (9M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGRjyWuml1nD"
      },
      "outputs": [],
      "source": [
        "def run_forecast_chronos_bolt_tiny(crsp_train_lagged, crsp_test_lagged, lag, out_sample_start):\n",
        "    lag_days_list = [5, 21, 252, 512]\n",
        "    if lag not in lag_days_list:\n",
        "        raise ValueError(f\"Invalid lag. Please choose from {lag_days_list}.\")\n",
        "\n",
        "    all_results = []\n",
        "    all_predictions = []\n",
        "    df_test = crsp_test_lagged[crsp_test_lagged[\"date\"] >= out_sample_start].copy()\n",
        "\n",
        "    # Initialize lists\n",
        "    contexts, targets, records = [], [], []\n",
        "\n",
        "    for permno, grp in df_test.groupby(\"permno\"):\n",
        "        values = grp[\"excess_ret\"].values\n",
        "        dates = grp[\"date\"].values\n",
        "\n",
        "        # Efficient tensor creation\n",
        "        for i in range(len(values) - lag):\n",
        "            context = values[i:i + lag]\n",
        "            target = values[i + lag]\n",
        "            contexts.append(context)\n",
        "            targets.append(target)\n",
        "            records.append({\n",
        "                \"permno\": permno,\n",
        "                \"date\": dates[i + lag]\n",
        "            })\n",
        "\n",
        "    # Convert contexts to tensor directly\n",
        "    contexts = torch.tensor(contexts, dtype=torch.float32)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    model_name = \"amazon/chronos-bolt-tiny\"\n",
        "    pipeline = ChronosBoltPipeline.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"cpu\",\n",
        "        torch_dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # Use zero-shot forecasting with quantile prediction\n",
        "    preds = []\n",
        "\n",
        "    for ctx in tqdm(contexts, desc=f\"Processing {model_name} with lag={lag}\"):\n",
        "        quantiles, mean = pipeline.predict_quantiles(context=[ctx], prediction_length=1, quantile_levels=[0.5])\n",
        "        preds.append(mean.cpu().squeeze().item())  # Extract the mean value from the quantiles\n",
        "\n",
        "    results = pd.DataFrame(records)\n",
        "    results[\"y_true\"] = targets\n",
        "    results[\"y_pred\"] = preds\n",
        "\n",
        "    y_test = results[\"y_true\"]\n",
        "    y_pred = results[\"y_pred\"]\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    acc = (np.sign(y_test) == np.sign(y_pred)).mean()\n",
        "    up_mask = y_test > 0\n",
        "    down_mask = y_test < 0\n",
        "    acc_up = (np.sign(y_pred[up_mask]) == 1).mean() if up_mask.sum() > 0 else np.nan\n",
        "    acc_down = (np.sign(y_pred[down_mask]) == -1).mean() if down_mask.sum() > 0 else np.nan\n",
        "\n",
        "    result = pd.DataFrame([{\n",
        "        'Model': model_name,\n",
        "        'Lag': lag,\n",
        "        'R2': r2,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'Directional_Accuracy': acc,\n",
        "        'Upward_Accuracy': acc_up,\n",
        "        'Downward_Accuracy': acc_down\n",
        "    }])\n",
        "\n",
        "    result.to_csv(f\"chronosbolttiny_results_lag{lag}.csv\", index=False)\n",
        "    results.to_csv(f\"chronosbolttiny_results_lag{lag}_full.csv\", index=False)\n",
        "\n",
        "    all_results.append(result)\n",
        "    all_predictions.append(results)\n",
        "\n",
        "    final_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "    if all_predictions:\n",
        "        combined_preds = pd.concat(all_predictions, ignore_index=True)\n",
        "        crsp_test_lagged = crsp_test_lagged.merge(\n",
        "            combined_preds[['permno', 'date', 'y_pred']],\n",
        "            on=['permno', 'date'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Rename the merged 'y_pred' column to the desired lag-specific name\n",
        "        crsp_test_lagged.rename(columns={'y_pred': f'predicted_excess_returns_lag{lag}'}, inplace=True)\n",
        "\n",
        "    else:\n",
        "        crsp_test_lagged[f'predicted_excess_returns_lag{lag}'] = np.nan\n",
        "\n",
        "    return final_df, crsp_test_lagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "-l6Fy98igzCs",
        "outputId": "69c46f62-dc24-4505-f9fa-1c927119d09f"
      },
      "outputs": [],
      "source": [
        "# Lag 5\n",
        "lag = 5\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosbolttiny5 = run_forecast_chronos_bolt_tiny(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosbolttiny5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "GDLlnixBo-qO",
        "outputId": "936caf4a-af32-48bd-80c2-44dac60d8c21"
      },
      "outputs": [],
      "source": [
        "# Lag 21\n",
        "lag = 21\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosbolttiny21 = run_forecast_chronos_bolt_tiny(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosbolttiny21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "jiu_Cim7pFB1",
        "outputId": "2cdf64b5-2376-4b63-8e9b-dd801bf6e438"
      },
      "outputs": [],
      "source": [
        "# Lag 252\n",
        "lag = 252\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosbolttiny252 = run_forecast_chronos_bolt_tiny(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosbolttiny252)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "l0Zj1YXNpHUb",
        "outputId": "e7477d25-53b3-4cfd-e5fc-947adc4931da"
      },
      "outputs": [],
      "source": [
        "# Lag 512\n",
        "lag = 512\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosbolttiny512 = run_forecast_chronos_bolt_tiny(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosbolttiny512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHvTc9NjVC8M"
      },
      "source": [
        "## Chronos_bolt Tiny (9M) Portfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9VKkKoCpHI1"
      },
      "source": [
        "### Window Size 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "xHNkCuHppE0L",
        "outputId": "55e1c626-6836-4a4a-b7b8-94660a5063ab"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosbolttiny` to predict excess returns\n",
        "def chronosbolttiny_5_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[5]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosbolttiny\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_tiny(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosbolttiny_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosbolttiny model\n",
        "crsp_test_lagged = chronosbolttiny_5_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosbolttiny5  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_5_with_cost': [],\n",
        "    'cum_ES_return_5_with_cost': [],\n",
        "    'cum_ELS_return_5_with_cost': [],\n",
        "    'cum_VL_return_5_with_cost': [],\n",
        "    'cum_VS_return_5_with_cost': [],\n",
        "    'cum_VLS_return_5_with_cost': [],\n",
        "    'cum_EL_return_5_without_cost': [],\n",
        "    'cum_ES_return_5_without_cost': [],\n",
        "    'cum_ELS_return_5_without_cost': [],\n",
        "    'cum_VL_return_5_without_cost': [],\n",
        "    'cum_VS_return_5_without_cost': [],\n",
        "    'cum_VLS_return_5_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 5\n",
        "cum_EL_return_5_with_cost = 0\n",
        "cum_ES_return_5_with_cost = 0\n",
        "cum_ELS_return_5_with_cost = 0\n",
        "cum_VL_return_5_with_cost = 0\n",
        "cum_VS_return_5_with_cost = 0\n",
        "cum_VLS_return_5_with_cost = 0\n",
        "\n",
        "cum_EL_return_5_without_cost = 0\n",
        "cum_ES_return_5_without_cost = 0\n",
        "cum_ELS_return_5_without_cost = 0\n",
        "cum_VL_return_5_without_cost = 0\n",
        "cum_VS_return_5_without_cost = 0\n",
        "cum_VLS_return_5_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 5 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 5 (or any other lag if needed)\n",
        "    returns = compute_returns(group, f'chronosbolttiny_{5}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 5\n",
        "    cum_EL_return_5_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_5_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_5_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_5_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_5_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_5_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_5_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_5_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_5_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_5_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_5_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_5_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 5 portfolios\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_EL_return_5_with_cost'].append(cum_EL_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_ES_return_5_with_cost'].append(cum_ES_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_ELS_return_5_with_cost'].append(cum_ELS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_VL_return_5_with_cost'].append(cum_VL_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_VS_return_5_with_cost'].append(cum_VS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_VLS_return_5_with_cost'].append(cum_VLS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_EL_return_5_without_cost'].append(cum_EL_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_ES_return_5_without_cost'].append(cum_ES_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_ELS_return_5_without_cost'].append(cum_ELS_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_VL_return_5_without_cost'].append(cum_VL_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_VS_return_5_without_cost'].append(cum_VS_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny5['cum_VLS_return_5_without_cost'].append(cum_VLS_return_5_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 5\n",
        "cumulative_log_returns_chronosbolttiny_lag_5 = pd.DataFrame(cumulative_log_returns_by_date_chronosbolttiny5)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 5\n",
        "display(cumulative_log_returns_chronosbolttiny_lag_5.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosbolttiny_lag_5.to_csv(\"cumulative_log_chronosbolttiny_lag_5.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "VwQmCnNhpGQb",
        "outputId": "7b5b4579-46ab-465f-b396-656b9a17deff"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns (for other metrics)\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns (for volatility and standard deviation)\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_5_with_cost', 'cum_ES_return_5_with_cost', 'cum_ELS_return_5_with_cost',\n",
        "    'cum_VL_return_5_with_cost', 'cum_VS_return_5_with_cost', 'cum_VLS_return_5_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosbolttiny5_c = cumulative_log_returns_chronosbolttiny_lag_5[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosbolttiny5_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics (e.g., cumulative returns, Sharpe ratio)\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)  # Using percentage-based cost for volatility\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost (using percentage-based cost for standard deviation)\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosbolttiny5_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosbolttiny5_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_5_without_cost', 'cum_ES_return_5_without_cost', 'cum_ELS_return_5_without_cost',\n",
        "    'cum_VL_return_5_without_cost', 'cum_VS_return_5_without_cost', 'cum_VLS_return_5_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosbolttiny5_wc = cumulative_log_returns_chronosbolttiny_lag_5[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosbolttiny5_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosbolttiny5_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosbolttiny5_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosbolttiny5_c.to_csv('metrics_chronosbolttiny5_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosbolttiny5_wc.to_csv('metrics_chronosbolttiny5_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63CroKZBumLm"
      },
      "source": [
        "### Window Size 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "QGx6Xw6RunJ-",
        "outputId": "8fc33a7a-ce37-4cb3-bb5d-14d5a17d9642"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosbolttiny` to predict excess returns\n",
        "def chronosbolttiny_21_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[21]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosbolttiny\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_tiny(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosbolttiny_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosbolttiny model\n",
        "crsp_test_lagged = chronosbolttiny_21_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Step 5: Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosbolttiny21  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_21_with_cost': [],\n",
        "    'cum_ES_return_21_with_cost': [],\n",
        "    'cum_ELS_return_21_with_cost': [],\n",
        "    'cum_VL_return_21_with_cost': [],\n",
        "    'cum_VS_return_21_with_cost': [],\n",
        "    'cum_VLS_return_21_with_cost': [],\n",
        "    'cum_EL_return_21_without_cost': [],\n",
        "    'cum_ES_return_21_without_cost': [],\n",
        "    'cum_ELS_return_21_without_cost': [],\n",
        "    'cum_VL_return_21_without_cost': [],\n",
        "    'cum_VS_return_21_without_cost': [],\n",
        "    'cum_VLS_return_21_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 21\n",
        "cum_EL_return_21_with_cost = 0\n",
        "cum_ES_return_21_with_cost = 0\n",
        "cum_ELS_return_21_with_cost = 0\n",
        "cum_VL_return_21_with_cost = 0\n",
        "cum_VS_return_21_with_cost = 0\n",
        "cum_VLS_return_21_with_cost = 0\n",
        "\n",
        "cum_EL_return_21_without_cost = 0\n",
        "cum_ES_return_21_without_cost = 0\n",
        "cum_ELS_return_21_without_cost = 0\n",
        "cum_VL_return_21_without_cost = 0\n",
        "cum_VS_return_21_without_cost = 0\n",
        "cum_VLS_return_21_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 21 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 21\n",
        "    returns = compute_returns(group, f'chronosbolttiny_{21}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 21\n",
        "    cum_EL_return_21_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_21_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_21_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_21_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_21_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_21_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_21_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_21_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_21_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_21_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_21_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_21_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 21 portfolios\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_EL_return_21_with_cost'].append(cum_EL_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_ES_return_21_with_cost'].append(cum_ES_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_ELS_return_21_with_cost'].append(cum_ELS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_VL_return_21_with_cost'].append(cum_VL_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_VS_return_21_with_cost'].append(cum_VS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_VLS_return_21_with_cost'].append(cum_VLS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_EL_return_21_without_cost'].append(cum_EL_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_ES_return_21_without_cost'].append(cum_ES_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_ELS_return_21_without_cost'].append(cum_ELS_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_VL_return_21_without_cost'].append(cum_VL_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_VS_return_21_without_cost'].append(cum_VS_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny21['cum_VLS_return_21_without_cost'].append(cum_VLS_return_21_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 21\n",
        "cumulative_log_returns_chronosbolttiny_lag_21 = pd.DataFrame(cumulative_log_returns_by_date_chronosbolttiny21)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 21\n",
        "display(cumulative_log_returns_chronosbolttiny_lag_21.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosbolttiny_lag_21.to_csv(\"cumulative_log_chronosbolttiny_lag_21.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "YGmnN--1vHZM",
        "outputId": "c11451a1-1446-42d0-c662-59f26ce9cdfe"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns (for other metrics)\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns (for volatility and standard deviation)\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_21_with_cost', 'cum_ES_return_21_with_cost', 'cum_ELS_return_21_with_cost',\n",
        "    'cum_VL_return_21_with_cost', 'cum_VS_return_21_with_cost', 'cum_VLS_return_21_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosbolttiny21_c = cumulative_log_returns_chronosbolttiny_lag_21[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosbolttiny21_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics (e.g., cumulative returns, Sharpe ratio)\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)  # Using percentage-based cost for volatility\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost (using percentage-based cost for standard deviation)\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosbolttiny21_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosbolttiny21_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_21_without_cost', 'cum_ES_return_21_without_cost', 'cum_ELS_return_21_without_cost',\n",
        "    'cum_VL_return_21_without_cost', 'cum_VS_return_21_without_cost', 'cum_VLS_return_21_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosbolttiny21_wc = cumulative_log_returns_chronosbolttiny_lag_21[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosbolttiny21_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosbolttiny21_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosbolttiny21_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosbolttiny21_c.to_csv('metrics_chronosbolttiny21_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosbolttiny21_wc.to_csv('metrics_chronosbolttiny21_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sns-5c9Z4N89"
      },
      "source": [
        "### Window Size 252"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "e7f53835fa1540c59983b0d09e6b8c37",
            "08c424343999428080a91a5df3a1616f"
          ]
        },
        "id": "rqxCex3S4PMd",
        "outputId": "589ba894-fb2e-496c-ddd3-69ee4ddd44e2"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosbolttiny` to predict excess returns\n",
        "def chronosbolttiny_252_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[252]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosbolttiny\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_tiny(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosbolttiny_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosbolttiny model\n",
        "crsp_test_lagged = chronosbolttiny_252_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosbolttiny252  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_252_with_cost': [],\n",
        "    'cum_ES_return_252_with_cost': [],\n",
        "    'cum_ELS_return_252_with_cost': [],\n",
        "    'cum_VL_return_252_with_cost': [],\n",
        "    'cum_VS_return_252_with_cost': [],\n",
        "    'cum_VLS_return_252_with_cost': [],\n",
        "    'cum_EL_return_252_without_cost': [],\n",
        "    'cum_ES_return_252_without_cost': [],\n",
        "    'cum_ELS_return_252_without_cost': [],\n",
        "    'cum_VL_return_252_without_cost': [],\n",
        "    'cum_VS_return_252_without_cost': [],\n",
        "    'cum_VLS_return_252_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 252\n",
        "cum_EL_return_252_with_cost = 0\n",
        "cum_ES_return_252_with_cost = 0\n",
        "cum_ELS_return_252_with_cost = 0\n",
        "cum_VL_return_252_with_cost = 0\n",
        "cum_VS_return_252_with_cost = 0\n",
        "cum_VLS_return_252_with_cost = 0\n",
        "\n",
        "cum_EL_return_252_without_cost = 0\n",
        "cum_ES_return_252_without_cost = 0\n",
        "cum_ELS_return_252_without_cost = 0\n",
        "cum_VL_return_252_without_cost = 0\n",
        "cum_VS_return_252_without_cost = 0\n",
        "cum_VLS_return_252_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 252 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 252\n",
        "    returns = compute_returns(group, f'chronosbolttiny_{252}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 252\n",
        "    cum_EL_return_252_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_252_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_252_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_252_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_252_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_252_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_252_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_252_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_252_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_252_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_252_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_252_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 252 portfolios\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_EL_return_252_with_cost'].append(cum_EL_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_ES_return_252_with_cost'].append(cum_ES_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_ELS_return_252_with_cost'].append(cum_ELS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_VL_return_252_with_cost'].append(cum_VL_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_VS_return_252_with_cost'].append(cum_VS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_VLS_return_252_with_cost'].append(cum_VLS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_EL_return_252_without_cost'].append(cum_EL_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_ES_return_252_without_cost'].append(cum_ES_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_ELS_return_252_without_cost'].append(cum_ELS_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_VL_return_252_without_cost'].append(cum_VL_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_VS_return_252_without_cost'].append(cum_VS_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny252['cum_VLS_return_252_without_cost'].append(cum_VLS_return_252_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 252\n",
        "cumulative_log_returns_chronosbolttiny_lag_252 = pd.DataFrame(cumulative_log_returns_by_date_chronosbolttiny252)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 252\n",
        "display(cumulative_log_returns_chronosbolttiny_lag_252.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosbolttiny_lag_252.to_csv(\"cumulative_log_chronosbolttiny_lag_252.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "Vy2P33XB49SZ",
        "outputId": "ff3628f3-f4c6-4f6b-81e7-6e07615b6edd"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns (for other metrics)\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns (for volatility and standard deviation)\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_252_with_cost', 'cum_ES_return_252_with_cost', 'cum_ELS_return_252_with_cost',\n",
        "    'cum_VL_return_252_with_cost', 'cum_VS_return_252_with_cost', 'cum_VLS_return_252_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosbolttiny252_c = cumulative_log_returns_chronosbolttiny_lag_252[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosbolttiny252_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics (e.g., cumulative returns, Sharpe ratio)\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosbolttiny252_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosbolttiny252_c)\n",
        "\n",
        "\n",
        "# Now, the same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_252_without_cost', 'cum_ES_return_252_without_cost', 'cum_ELS_return_252_without_cost',\n",
        "    'cum_VL_return_252_without_cost', 'cum_VS_return_252_without_cost', 'cum_VLS_return_252_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosbolttiny252_wc = cumulative_log_returns_chronosbolttiny_lag_252[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosbolttiny252_wc)\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosbolttiny252_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosbolttiny252_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosbolttiny252_c.to_csv('metrics_chronosbolttiny252_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosbolttiny252_wc.to_csv('metrics_chronosbolttiny252_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tm133B471_K"
      },
      "source": [
        "### Window Size 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "V2aop3R97224",
        "outputId": "25abd6be-902f-44ad-a50b-52c268eb8503"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosbolttiny` to predict excess returns\n",
        "def chronosbolttiny_512_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[512]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosbolttiny\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_tiny(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosbolttiny_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosbolttiny model\n",
        "crsp_test_lagged = chronosbolttiny_512_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosbolttiny512  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_512_with_cost': [],\n",
        "    'cum_ES_return_512_with_cost': [],\n",
        "    'cum_ELS_return_512_with_cost': [],\n",
        "    'cum_VL_return_512_with_cost': [],\n",
        "    'cum_VS_return_512_with_cost': [],\n",
        "    'cum_VLS_return_512_with_cost': [],\n",
        "    'cum_EL_return_512_without_cost': [],\n",
        "    'cum_ES_return_512_without_cost': [],\n",
        "    'cum_ELS_return_512_without_cost': [],\n",
        "    'cum_VL_return_512_without_cost': [],\n",
        "    'cum_VS_return_512_without_cost': [],\n",
        "    'cum_VLS_return_512_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 512\n",
        "cum_EL_return_512_with_cost = 0\n",
        "cum_ES_return_512_with_cost = 0\n",
        "cum_ELS_return_512_with_cost = 0\n",
        "cum_VL_return_512_with_cost = 0\n",
        "cum_VS_return_512_with_cost = 0\n",
        "cum_VLS_return_512_with_cost = 0\n",
        "\n",
        "cum_EL_return_512_without_cost = 0\n",
        "cum_ES_return_512_without_cost = 0\n",
        "cum_ELS_return_512_without_cost = 0\n",
        "cum_VL_return_512_without_cost = 0\n",
        "cum_VS_return_512_without_cost = 0\n",
        "cum_VLS_return_512_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 512 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 512\n",
        "    returns = compute_returns(group, f'chronosbolttiny_{512}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 512\n",
        "    cum_EL_return_512_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_512_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_512_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_512_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_512_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_512_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_512_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_512_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_512_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_512_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_512_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_512_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 512 portfolios\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_EL_return_512_with_cost'].append(cum_EL_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_ES_return_512_with_cost'].append(cum_ES_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_ELS_return_512_with_cost'].append(cum_ELS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_VL_return_512_with_cost'].append(cum_VL_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_VS_return_512_with_cost'].append(cum_VS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_VLS_return_512_with_cost'].append(cum_VLS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_EL_return_512_without_cost'].append(cum_EL_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_ES_return_512_without_cost'].append(cum_ES_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_ELS_return_512_without_cost'].append(cum_ELS_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_VL_return_512_without_cost'].append(cum_VL_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_VS_return_512_without_cost'].append(cum_VS_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosbolttiny512['cum_VLS_return_512_without_cost'].append(cum_VLS_return_512_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 512\n",
        "cumulative_log_returns_chronosbolttiny_lag_512 = pd.DataFrame(cumulative_log_returns_by_date_chronosbolttiny512)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 512\n",
        "display(cumulative_log_returns_chronosbolttiny_lag_512.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosbolttiny_lag_512.to_csv(\"cumulative_log_chronosbolttiny_lag_512.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "XFEYYjx4-_ZY",
        "outputId": "aefc676a-16c0-4872-867c-894da28b1675"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_512_with_cost', 'cum_ES_return_512_with_cost', 'cum_ELS_return_512_with_cost',\n",
        "    'cum_VL_return_512_with_cost', 'cum_VS_return_512_with_cost', 'cum_VLS_return_512_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosbolttiny512_c = cumulative_log_returns_chronosbolttiny_lag_512[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosbolttiny512_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)  # Using percentage-based cost for volatility\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost (using percentage-based cost for standard deviation)\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosbolttiny512_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosbolttiny512_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_512_without_cost', 'cum_ES_return_512_without_cost', 'cum_ELS_return_512_without_cost',\n",
        "    'cum_VL_return_512_without_cost', 'cum_VS_return_512_without_cost', 'cum_VLS_return_512_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosbolttiny512_wc = cumulative_log_returns_chronosbolttiny_lag_512[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosbolttiny512_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosbolttiny512_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosbolttiny512_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosbolttiny512_c.to_csv('metrics_chronosbolttiny512_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosbolttiny512_wc.to_csv('metrics_chronosbolttiny512_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wibh-dQ3pfks"
      },
      "source": [
        "## Chronos_bolt Mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dcw_EhAXpoxl"
      },
      "outputs": [],
      "source": [
        "def run_forecast_chronos_bolt_mini(crsp_train_lagged, crsp_test_lagged, lag, out_sample_start):\n",
        "    lag_days_list = [5, 21, 252, 512]\n",
        "    if lag not in lag_days_list:\n",
        "        raise ValueError(f\"Invalid lag. Please choose from {lag_days_list}.\")\n",
        "\n",
        "    all_results = []\n",
        "    all_predictions = []\n",
        "    df_test = crsp_test_lagged[crsp_test_lagged[\"date\"] >= out_sample_start].copy()\n",
        "\n",
        "    # Initialize lists\n",
        "    contexts, targets, records = [], [], []\n",
        "\n",
        "    for permno, grp in df_test.groupby(\"permno\"):\n",
        "        values = grp[\"excess_ret\"].values\n",
        "        dates = grp[\"date\"].values\n",
        "\n",
        "        # Efficient tensor creation\n",
        "        for i in range(len(values) - lag):\n",
        "            context = values[i:i + lag]\n",
        "            target = values[i + lag]\n",
        "            contexts.append(context)\n",
        "            targets.append(target)\n",
        "            records.append({\n",
        "                \"permno\": permno,\n",
        "                \"date\": dates[i + lag]\n",
        "            })\n",
        "\n",
        "    # Convert contexts to tensor directly\n",
        "    contexts = torch.tensor(contexts, dtype=torch.float32)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    model_name = \"amazon/chronos-bolt-mini\"\n",
        "    pipeline = ChronosBoltPipeline.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"cpu\",\n",
        "        torch_dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # Use zero-shot forecasting with quantile prediction\n",
        "    preds = []\n",
        "\n",
        "    for ctx in tqdm(contexts, desc=f\"Processing {model_name} with lag={lag}\"):\n",
        "        quantiles, mean = pipeline.predict_quantiles(context=[ctx], prediction_length=1, quantile_levels=[0.5])\n",
        "        preds.append(mean.cpu().squeeze().item())  # Extract the mean value from the quantiles\n",
        "\n",
        "    results = pd.DataFrame(records)\n",
        "    results[\"y_true\"] = targets\n",
        "    results[\"y_pred\"] = preds\n",
        "\n",
        "    y_test = results[\"y_true\"]\n",
        "    y_pred = results[\"y_pred\"]\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    acc = (np.sign(y_test) == np.sign(y_pred)).mean()\n",
        "    up_mask = y_test > 0\n",
        "    down_mask = y_test < 0\n",
        "    acc_up = (np.sign(y_pred[up_mask]) == 1).mean() if up_mask.sum() > 0 else np.nan\n",
        "    acc_down = (np.sign(y_pred[down_mask]) == -1).mean() if down_mask.sum() > 0 else np.nan\n",
        "\n",
        "    result = pd.DataFrame([{\n",
        "        'Model': model_name,\n",
        "        'Lag': lag,\n",
        "        'R2': r2,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'Directional_Accuracy': acc,\n",
        "        'Upward_Accuracy': acc_up,\n",
        "        'Downward_Accuracy': acc_down\n",
        "    }])\n",
        "\n",
        "    result.to_csv(f\"chronosboltmini_results_lag{lag}.csv\", index=False)\n",
        "    results.to_csv(f\"chronosboltmini_results_lag{lag}_full.csv\", index=False)\n",
        "\n",
        "    all_results.append(result)\n",
        "    all_predictions.append(results)\n",
        "\n",
        "    final_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "    if all_predictions:\n",
        "        combined_preds = pd.concat(all_predictions, ignore_index=True)\n",
        "        crsp_test_lagged = crsp_test_lagged.merge(\n",
        "            combined_preds[['permno', 'date', 'y_pred']],\n",
        "            on=['permno', 'date'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Rename the merged 'y_pred' column to the desired lag-specific name\n",
        "        crsp_test_lagged.rename(columns={'y_pred': f'predicted_excess_returns_lag{lag}'}, inplace=True)\n",
        "\n",
        "    else:\n",
        "        crsp_test_lagged[f'predicted_excess_returns_lag{lag}'] = np.nan\n",
        "\n",
        "    return final_df, crsp_test_lagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "8490e95ad9994bfe9ff587407bd481d7",
            "bdaa841dcdf543dd8b8c171eebf20662"
          ]
        },
        "id": "1GVZ_x6BpTmc",
        "outputId": "95d29dd3-36d8-440a-84b7-78f3e990dba9"
      },
      "outputs": [],
      "source": [
        "# Lag 5\n",
        "lag = 5\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosboltmini5 = run_forecast_chronos_bolt_mini(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosboltmini5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "BbrTs2O1pmKB",
        "outputId": "85da5bc6-f5a0-4567-a41b-036f516b5bfa"
      },
      "outputs": [],
      "source": [
        "# Lag 21\n",
        "lag = 21\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosboltmini21 = run_forecast_chronos_bolt_mini(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosboltmini21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "q2cjd0wzpr3e",
        "outputId": "d848d532-2283-4203-b55a-585b39a2caa5"
      },
      "outputs": [],
      "source": [
        "# Lag 252\n",
        "lag = 252\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosboltmini252 = run_forecast_chronos_bolt_mini(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosboltmini252)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "kKJ4dYBdpsZq",
        "outputId": "359508a4-86a7-414c-aaab-51556c3672a3"
      },
      "outputs": [],
      "source": [
        "# Lag 512\n",
        "lag = 512\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosboltmini512 = run_forecast_chronos_bolt_mini(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosboltmini512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuYmwGsQIXT_"
      },
      "source": [
        "## Chronos_bolt Mini Portfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "152IP6jdIkCM"
      },
      "source": [
        "### Window Size 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "48198cadea7c4a159411a5904b1f730c",
            "e8e94edeeec04d5c90b55448d9a90812"
          ]
        },
        "id": "W6cSPGR1IjIC",
        "outputId": "9d263484-16b5-45e6-a766-a246ece45bec"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosboltmini` to predict excess returns\n",
        "def chronosboltmini_5_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[5]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosboltmini\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_mini(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosboltmini_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosboltmini model\n",
        "crsp_test_lagged = chronosboltmini_5_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosboltmini5  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_5_with_cost': [],\n",
        "    'cum_ES_return_5_with_cost': [],\n",
        "    'cum_ELS_return_5_with_cost': [],\n",
        "    'cum_VL_return_5_with_cost': [],\n",
        "    'cum_VS_return_5_with_cost': [],\n",
        "    'cum_VLS_return_5_with_cost': [],\n",
        "    'cum_EL_return_5_without_cost': [],\n",
        "    'cum_ES_return_5_without_cost': [],\n",
        "    'cum_ELS_return_5_without_cost': [],\n",
        "    'cum_VL_return_5_without_cost': [],\n",
        "    'cum_VS_return_5_without_cost': [],\n",
        "    'cum_VLS_return_5_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 5\n",
        "cum_EL_return_5_with_cost = 0\n",
        "cum_ES_return_5_with_cost = 0\n",
        "cum_ELS_return_5_with_cost = 0\n",
        "cum_VL_return_5_with_cost = 0\n",
        "cum_VS_return_5_with_cost = 0\n",
        "cum_VLS_return_5_with_cost = 0\n",
        "\n",
        "cum_EL_return_5_without_cost = 0\n",
        "cum_ES_return_5_without_cost = 0\n",
        "cum_ELS_return_5_without_cost = 0\n",
        "cum_VL_return_5_without_cost = 0\n",
        "cum_VS_return_5_without_cost = 0\n",
        "cum_VLS_return_5_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 5 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 5 (or any other lag if needed)\n",
        "    returns = compute_returns(group, f'chronosboltmini_{5}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 5\n",
        "    cum_EL_return_5_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_5_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_5_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_5_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_5_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_5_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_5_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_5_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_5_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_5_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_5_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_5_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 5 portfolios\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_EL_return_5_with_cost'].append(cum_EL_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_ES_return_5_with_cost'].append(cum_ES_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_ELS_return_5_with_cost'].append(cum_ELS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_VL_return_5_with_cost'].append(cum_VL_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_VS_return_5_with_cost'].append(cum_VS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_VLS_return_5_with_cost'].append(cum_VLS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_EL_return_5_without_cost'].append(cum_EL_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_ES_return_5_without_cost'].append(cum_ES_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_ELS_return_5_without_cost'].append(cum_ELS_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_VL_return_5_without_cost'].append(cum_VL_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_VS_return_5_without_cost'].append(cum_VS_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini5['cum_VLS_return_5_without_cost'].append(cum_VLS_return_5_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 5\n",
        "cumulative_log_returns_chronosboltmini_lag_5 = pd.DataFrame(cumulative_log_returns_by_date_chronosboltmini5)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 5\n",
        "display(cumulative_log_returns_chronosboltmini_lag_5.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosboltmini_lag_5.to_csv(\"cumulative_log_chronosboltmini_lag_5.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "dyZFMM8gHbIR",
        "outputId": "16ff5b6f-f24b-4321-e5c8-4d0241f17b73"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_5_with_cost', 'cum_ES_return_5_with_cost', 'cum_ELS_return_5_with_cost',\n",
        "    'cum_VL_return_5_with_cost', 'cum_VS_return_5_with_cost', 'cum_VLS_return_5_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosboltmini5_c = cumulative_log_returns_chronosboltmini_lag_5[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltmini5_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)  # Using percentage-based cost for volatility\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltmini5_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosboltmini5_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_5_without_cost', 'cum_ES_return_5_without_cost', 'cum_ELS_return_5_without_cost',\n",
        "    'cum_VL_return_5_without_cost', 'cum_VS_return_5_without_cost', 'cum_VLS_return_5_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosboltmini5_wc = cumulative_log_returns_chronosboltmini_lag_5[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltmini5_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltmini5_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosboltmini5_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosboltmini5_c.to_csv('metrics_chronosboltmini5_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosboltmini5_wc.to_csv('metrics_chronosboltmini5_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQdy21ugJIVv"
      },
      "source": [
        "### Window Size 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "oby-To-0JJT-",
        "outputId": "978ff1e8-cbbd-4918-9700-b1526f8e421c"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `Chronos Bolt Mini` to predict excess returns\n",
        "def chronosboltmini_21_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[21]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to run_forecast_chronos_bolt_mini\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_mini(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col in modified_crsp_test_lagged.columns:\n",
        "\n",
        "            modified_crsp_test_lagged[f'chronosboltmini_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "        else:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using Chronos Bolt Mini model\n",
        "crsp_test_lagged = chronosboltmini_21_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosboltmini21  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_21_with_cost': [],\n",
        "    'cum_ES_return_21_with_cost': [],\n",
        "    'cum_ELS_return_21_with_cost': [],\n",
        "    'cum_VL_return_21_with_cost': [],\n",
        "    'cum_VS_return_21_with_cost': [],\n",
        "    'cum_VLS_return_21_with_cost': [],\n",
        "    'cum_EL_return_21_without_cost': [],\n",
        "    'cum_ES_return_21_without_cost': [],\n",
        "    'cum_ELS_return_21_without_cost': [],\n",
        "    'cum_VL_return_21_without_cost': [],\n",
        "    'cum_VS_return_21_without_cost': [],\n",
        "    'cum_VLS_return_21_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 21\n",
        "cum_EL_return_21_with_cost = 0\n",
        "cum_ES_return_21_with_cost = 0\n",
        "cum_ELS_return_21_with_cost = 0\n",
        "cum_VL_return_21_with_cost = 0\n",
        "cum_VS_return_21_with_cost = 0\n",
        "cum_VLS_return_21_with_cost = 0\n",
        "\n",
        "cum_EL_return_21_without_cost = 0\n",
        "cum_ES_return_21_without_cost = 0\n",
        "cum_ELS_return_21_without_cost = 0\n",
        "cum_VL_return_21_without_cost = 0\n",
        "cum_VS_return_21_without_cost = 0\n",
        "cum_VLS_return_21_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 21 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 21 (or any other lag if needed)\n",
        "    returns = compute_returns(group, f'chronosboltmini_{21}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 21\n",
        "    cum_EL_return_21_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_21_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_21_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_21_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_21_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_21_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_21_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_21_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_21_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_21_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_21_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_21_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 21 portfolios\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_EL_return_21_with_cost'].append(cum_EL_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_ES_return_21_with_cost'].append(cum_ES_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_ELS_return_21_with_cost'].append(cum_ELS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_VL_return_21_with_cost'].append(cum_VL_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_VS_return_21_with_cost'].append(cum_VS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_VLS_return_21_with_cost'].append(cum_VLS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_EL_return_21_without_cost'].append(cum_EL_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_ES_return_21_without_cost'].append(cum_ES_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_ELS_return_21_without_cost'].append(cum_ELS_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_VL_return_21_without_cost'].append(cum_VL_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_VS_return_21_without_cost'].append(cum_VS_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini21['cum_VLS_return_21_without_cost'].append(cum_VLS_return_21_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 21\n",
        "cumulative_log_returns_chronosboltmini_lag_21 = pd.DataFrame(cumulative_log_returns_by_date_chronosboltmini21)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 21\n",
        "display(cumulative_log_returns_chronosboltmini_lag_21.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosboltmini_lag_21.to_csv(\"cumulative_log_chronosboltmini_lag_21.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "-wZTjQAHP62N",
        "outputId": "8e1cdb7f-6967-4ca3-cd85-959e3f14e840"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns (for other metrics)\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns (for volatility and standard deviation)\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_21_with_cost', 'cum_ES_return_21_with_cost', 'cum_ELS_return_21_with_cost',\n",
        "    'cum_VL_return_21_with_cost', 'cum_VS_return_21_with_cost', 'cum_VLS_return_21_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosboltmini21_c = cumulative_log_returns_chronosboltmini_lag_21[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltmini21_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltmini21_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosboltmini21_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_21_without_cost', 'cum_ES_return_21_without_cost', 'cum_ELS_return_21_without_cost',\n",
        "    'cum_VL_return_21_without_cost', 'cum_VS_return_21_without_cost', 'cum_VLS_return_21_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosboltmini21_wc = cumulative_log_returns_chronosboltmini_lag_21[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltmini21_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltmini21_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosboltmini21_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosboltmini21_c.to_csv('metrics_chronosboltmini21_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosboltmini21_wc.to_csv('metrics_chronosboltmini21_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwrrRQt4P5_i"
      },
      "source": [
        "### Window Size 252"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "LqK6qANJQKz-",
        "outputId": "d7ca756f-4767-4754-e1f9-b655207a949a"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosboltmini` to predict excess returns\n",
        "def chronosboltmini_252_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[252]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosboltmini\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_mini(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosboltmini_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosboltmini model\n",
        "crsp_test_lagged = chronosboltmini_252_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosboltmini252  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_252_with_cost': [],\n",
        "    'cum_ES_return_252_with_cost': [],\n",
        "    'cum_ELS_return_252_with_cost': [],\n",
        "    'cum_VL_return_252_with_cost': [],\n",
        "    'cum_VS_return_252_with_cost': [],\n",
        "    'cum_VLS_return_252_with_cost': [],\n",
        "    'cum_EL_return_252_without_cost': [],\n",
        "    'cum_ES_return_252_without_cost': [],\n",
        "    'cum_ELS_return_252_without_cost': [],\n",
        "    'cum_VL_return_252_without_cost': [],\n",
        "    'cum_VS_return_252_without_cost': [],\n",
        "    'cum_VLS_return_252_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 252\n",
        "cum_EL_return_252_with_cost = 0\n",
        "cum_ES_return_252_with_cost = 0\n",
        "cum_ELS_return_252_with_cost = 0\n",
        "cum_VL_return_252_with_cost = 0\n",
        "cum_VS_return_252_with_cost = 0\n",
        "cum_VLS_return_252_with_cost = 0\n",
        "\n",
        "cum_EL_return_252_without_cost = 0\n",
        "cum_ES_return_252_without_cost = 0\n",
        "cum_ELS_return_252_without_cost = 0\n",
        "cum_VL_return_252_without_cost = 0\n",
        "cum_VS_return_252_without_cost = 0\n",
        "cum_VLS_return_252_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 252 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 252\n",
        "    returns = compute_returns(group, f'chronosboltmini_{252}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 252\n",
        "    cum_EL_return_252_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_252_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_252_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_252_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_252_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_252_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_252_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_252_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_252_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_252_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_252_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_252_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 252 portfolios\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_EL_return_252_with_cost'].append(cum_EL_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_ES_return_252_with_cost'].append(cum_ES_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_ELS_return_252_with_cost'].append(cum_ELS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_VL_return_252_with_cost'].append(cum_VL_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_VS_return_252_with_cost'].append(cum_VS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_VLS_return_252_with_cost'].append(cum_VLS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_EL_return_252_without_cost'].append(cum_EL_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_ES_return_252_without_cost'].append(cum_ES_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_ELS_return_252_without_cost'].append(cum_ELS_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_VL_return_252_without_cost'].append(cum_VL_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_VS_return_252_without_cost'].append(cum_VS_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini252['cum_VLS_return_252_without_cost'].append(cum_VLS_return_252_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 252\n",
        "cumulative_log_returns_chronosboltmini_lag_252 = pd.DataFrame(cumulative_log_returns_by_date_chronosboltmini252)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 252\n",
        "display(cumulative_log_returns_chronosboltmini_lag_252.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosboltmini_lag_252.to_csv(\"cumulative_log_chronosboltmini_lag_252.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "F2nur-YTQrRT",
        "outputId": "5997ce1f-b142-4010-a251-a19076f63c0d"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns (for other metrics)\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns (for volatility and standard deviation)\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_252_with_cost', 'cum_ES_return_252_with_cost', 'cum_ELS_return_252_with_cost',\n",
        "    'cum_VL_return_252_with_cost', 'cum_VS_return_252_with_cost', 'cum_VLS_return_252_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosboltmini252_c = cumulative_log_returns_chronosboltmini_lag_252[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltmini252_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics (e.g., cumulative returns, Sharpe ratio)\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)  # Using percentage-based cost for volatility\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost (using percentage-based cost for standard deviation)\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltmini252_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosboltmini252_c)\n",
        "\n",
        "# the same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_252_without_cost', 'cum_ES_return_252_without_cost', 'cum_ELS_return_252_without_cost',\n",
        "    'cum_VL_return_252_without_cost', 'cum_VS_return_252_without_cost', 'cum_VLS_return_252_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosboltmini252_wc = cumulative_log_returns_chronosboltmini_lag_252[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltmini252_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltmini252_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosboltmini252_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosboltmini252_c.to_csv('metrics_chronosboltmini252_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosboltmini252_wc.to_csv('metrics_chronosboltmini252_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIGfFvT6RRaI"
      },
      "source": [
        "### Window Size 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "bzUE8wIYRSlK",
        "outputId": "674744ac-ab6c-4a54-8779-4b067e75dd16"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosboltmini` to predict excess returns\n",
        "def chronosboltmini_512_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[512]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosboltmini\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_mini(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosboltmini_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosboltmini_ model\n",
        "crsp_test_lagged = chronosboltmini_512_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosboltmini512  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_512_with_cost': [],\n",
        "    'cum_ES_return_512_with_cost': [],\n",
        "    'cum_ELS_return_512_with_cost': [],\n",
        "    'cum_VL_return_512_with_cost': [],\n",
        "    'cum_VS_return_512_with_cost': [],\n",
        "    'cum_VLS_return_512_with_cost': [],\n",
        "    'cum_EL_return_512_without_cost': [],\n",
        "    'cum_ES_return_512_without_cost': [],\n",
        "    'cum_ELS_return_512_without_cost': [],\n",
        "    'cum_VL_return_512_without_cost': [],\n",
        "    'cum_VS_return_512_without_cost': [],\n",
        "    'cum_VLS_return_512_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 512\n",
        "cum_EL_return_512_with_cost = 0\n",
        "cum_ES_return_512_with_cost = 0\n",
        "cum_ELS_return_512_with_cost = 0\n",
        "cum_VL_return_512_with_cost = 0\n",
        "cum_VS_return_512_with_cost = 0\n",
        "cum_VLS_return_512_with_cost = 0\n",
        "\n",
        "cum_EL_return_512_without_cost = 0\n",
        "cum_ES_return_512_without_cost = 0\n",
        "cum_ELS_return_512_without_cost = 0\n",
        "cum_VL_return_512_without_cost = 0\n",
        "cum_VS_return_512_without_cost = 0\n",
        "cum_VLS_return_512_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 512 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 512\n",
        "    returns = compute_returns(group, f'chronosboltmini_{512}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 512\n",
        "    cum_EL_return_512_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_512_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_512_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_512_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_512_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_512_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_512_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_512_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_512_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_512_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_512_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_512_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 512 portfolios\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_EL_return_512_with_cost'].append(cum_EL_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_ES_return_512_with_cost'].append(cum_ES_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_ELS_return_512_with_cost'].append(cum_ELS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_VL_return_512_with_cost'].append(cum_VL_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_VS_return_512_with_cost'].append(cum_VS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_VLS_return_512_with_cost'].append(cum_VLS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_EL_return_512_without_cost'].append(cum_EL_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_ES_return_512_without_cost'].append(cum_ES_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_ELS_return_512_without_cost'].append(cum_ELS_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_VL_return_512_without_cost'].append(cum_VL_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_VS_return_512_without_cost'].append(cum_VS_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltmini512['cum_VLS_return_512_without_cost'].append(cum_VLS_return_512_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 512\n",
        "cumulative_log_returns_chronosboltmini_lag_512 = pd.DataFrame(cumulative_log_returns_by_date_chronosboltmini512)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 512\n",
        "display(cumulative_log_returns_chronosboltmini_lag_512.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosboltmini_lag_512.to_csv(\"cumulative_log_chronosboltmini_lag_512.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "Lw3XimbnyS9Y",
        "outputId": "e05d44c6-88be-495d-bd35-88263ba0c108"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns (for other metrics)\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns (for volatility and standard deviation)\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_512_with_cost', 'cum_ES_return_512_with_cost', 'cum_ELS_return_512_with_cost',\n",
        "    'cum_VL_return_512_with_cost', 'cum_VS_return_512_with_cost', 'cum_VLS_return_512_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosboltmini512_c = cumulative_log_returns_chronosboltmini_lag_512[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltmini512_c)\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltmini512_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosboltmini512_c)\n",
        "\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_512_without_cost', 'cum_ES_return_512_without_cost', 'cum_ELS_return_512_without_cost',\n",
        "    'cum_VL_return_512_without_cost', 'cum_VS_return_512_without_cost', 'cum_VLS_return_512_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosboltmini512_wc = cumulative_log_returns_chronosboltmini_lag_512[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltmini512_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltmini512_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosboltmini512_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosboltmini512_c.to_csv('metrics_chronosboltmini512_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosboltmini512_wc.to_csv('metrics_chronosboltmini512_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4m6mRo5tmCI"
      },
      "source": [
        "## Chronos_bolt Small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTJv2u1GtoBe"
      },
      "outputs": [],
      "source": [
        "def run_forecast_chronos_bolt_small(crsp_train_lagged, crsp_test_lagged, lag, out_sample_start):\n",
        "    lag_days_list = [5, 21, 252, 512]\n",
        "    if lag not in lag_days_list:\n",
        "        raise ValueError(f\"Invalid lag. Please choose from {lag_days_list}.\")\n",
        "\n",
        "    all_results = []\n",
        "    all_predictions = []\n",
        "    df_test = crsp_test_lagged[crsp_test_lagged[\"date\"] >= out_sample_start].copy()\n",
        "\n",
        "    # Initialize lists\n",
        "    contexts, targets, records = [], [], []\n",
        "\n",
        "    for permno, grp in df_test.groupby(\"permno\"):\n",
        "        values = grp[\"excess_ret\"].values\n",
        "        dates = grp[\"date\"].values\n",
        "\n",
        "        # Efficient tensor creation\n",
        "        for i in range(len(values) - lag):\n",
        "            context = values[i:i + lag]\n",
        "            target = values[i + lag]\n",
        "            contexts.append(context)\n",
        "            targets.append(target)\n",
        "            records.append({\n",
        "                \"permno\": permno,\n",
        "                \"date\": dates[i + lag]\n",
        "            })\n",
        "\n",
        "    # Convert contexts to tensor directly\n",
        "    contexts = torch.tensor(contexts, dtype=torch.float32)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    model_name = \"amazon/chronos-bolt-small\"\n",
        "    pipeline = ChronosBoltPipeline.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"cpu\",\n",
        "        torch_dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # Use zero-shot forecasting with quantile prediction\n",
        "    preds = []\n",
        "\n",
        "    for ctx in tqdm(contexts, desc=f\"Processing {model_name} with lag={lag}\"):\n",
        "        quantiles, mean = pipeline.predict_quantiles(context=[ctx], prediction_length=1, quantile_levels=[0.5])\n",
        "        preds.append(mean.cpu().squeeze().item())  # Extract the mean value from the quantiles\n",
        "\n",
        "    results = pd.DataFrame(records)\n",
        "    results[\"y_true\"] = targets\n",
        "    results[\"y_pred\"] = preds\n",
        "\n",
        "    y_test = results[\"y_true\"]\n",
        "    y_pred = results[\"y_pred\"]\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    acc = (np.sign(y_test) == np.sign(y_pred)).mean()\n",
        "    up_mask = y_test > 0\n",
        "    down_mask = y_test < 0\n",
        "    acc_up = (np.sign(y_pred[up_mask]) == 1).mean() if up_mask.sum() > 0 else np.nan\n",
        "    acc_down = (np.sign(y_pred[down_mask]) == -1).mean() if down_mask.sum() > 0 else np.nan\n",
        "\n",
        "    result = pd.DataFrame([{\n",
        "        'Model': model_name,\n",
        "        'Lag': lag,\n",
        "        'R2': r2,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'Directional_Accuracy': acc,\n",
        "        'Upward_Accuracy': acc_up,\n",
        "        'Downward_Accuracy': acc_down\n",
        "    }])\n",
        "\n",
        "    result.to_csv(f\"chronosboltsmall_results_lag{lag}.csv\", index=False)\n",
        "    results.to_csv(f\"chronosboltsmall_results_lag{lag}_full.csv\", index=False)\n",
        "\n",
        "    all_results.append(result)\n",
        "    all_predictions.append(results)\n",
        "\n",
        "    final_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "    if all_predictions:\n",
        "        combined_preds = pd.concat(all_predictions, ignore_index=True)\n",
        "        crsp_test_lagged = crsp_test_lagged.merge(\n",
        "            combined_preds[['permno', 'date', 'y_pred']],\n",
        "            on=['permno', 'date'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Rename the merged 'y_pred' column to the desired lag-specific name\n",
        "        crsp_test_lagged.rename(columns={'y_pred': f'predicted_excess_returns_lag{lag}'}, inplace=True)\n",
        "\n",
        "    else:\n",
        "        crsp_test_lagged[f'predicted_excess_returns_lag{lag}'] = np.nan\n",
        "\n",
        "    return final_df, crsp_test_lagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "07e61926bc634165addd8fe19b2e32ef",
            "a91220e0e0ec4e158201ecbeb32831e3"
          ]
        },
        "id": "ZjXnXVmnt0_H",
        "outputId": "c59a2693-a3a0-47dc-9cd9-bf97e59c42be"
      },
      "outputs": [],
      "source": [
        "# Lag 5\n",
        "lag = 5\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosboltsmall5 = run_forecast_chronos_bolt_small(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosboltsmall5)\n",
        "\n",
        "# Saving results to CSV\n",
        "result_df_chronosboltsmall5.to_csv('chronosboltsmall5_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "313dbbc3e660477d8326c7e9c3232d6e",
            "e7e7d9b25c4b47f798e2047825242ff0"
          ]
        },
        "id": "nlaUhpKRt55U",
        "outputId": "ee639b08-4eff-49a1-eb05-1888cb18377b"
      },
      "outputs": [],
      "source": [
        "# Lag 21\n",
        "lag = 21\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosboltsmall21 = run_forecast_chronos_bolt_small(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosboltsmall21)\n",
        "\n",
        "# Saving results to CSV\n",
        "result_df_chronosboltsmall21.to_csv('chronosboltsmall21_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "2acb8f6de5b54f759177b8848ee7a054",
            "73099bef76d24df3ae5bdfdfb314c2c0"
          ]
        },
        "id": "yFuTVPk8t9MF",
        "outputId": "b4c914f3-efba-4ba8-bff9-3f38a307aabd"
      },
      "outputs": [],
      "source": [
        "# Lag 252\n",
        "lag = 252\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosboltsmall252 = run_forecast_chronos_bolt_small(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosboltsmall252)\n",
        "\n",
        "# Saving results to CSV\n",
        "result_df_chronosboltsmall252.to_csv('chronosboltsmall252_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "vwgZtYJwt_th",
        "outputId": "966419a2-63c0-451d-cd9a-0876c6a80645"
      },
      "outputs": [],
      "source": [
        "# Lag 512\n",
        "lag = 512\n",
        "\n",
        "# Run the forecast with the specified lag\n",
        "result_df_chronosboltsmall512 = run_forecast_chronos_bolt_small(\n",
        "    crsp_train_lagged=crsp_train_lagged,\n",
        "    crsp_test_lagged=crsp_test_lagged,\n",
        "    lag=lag,\n",
        "    out_sample_start=\"2016-01-01\"\n",
        ")\n",
        "\n",
        "# Display the result\n",
        "display(result_df_chronosboltsmall512)\n",
        "\n",
        "# Saving results to CSV\n",
        "result_df_chronosboltsmall252.to_csv('chronosboltsmall252_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zx_-UrJgI84"
      },
      "source": [
        "## Chronos_bolt Small (48M) Portfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NvCy5zYgL3F"
      },
      "source": [
        "### Window Size 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "ff651595517c4a02991e0993d1b29d4b",
            "a3faae1f71e7483195755a2602ac711b"
          ]
        },
        "id": "ahhdkVb3hfTL",
        "outputId": "73e22f05-5450-4318-b820-de9be415c052"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosboltsmall` to predict excess returns\n",
        "def chronosboltsmall_5_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[5]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosboltsmall\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_small(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosboltsmall_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosboltsmall model\n",
        "crsp_test_lagged = chronosboltsmall_5_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosboltsmall5  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_5_with_cost': [],\n",
        "    'cum_ES_return_5_with_cost': [],\n",
        "    'cum_ELS_return_5_with_cost': [],\n",
        "    'cum_VL_return_5_with_cost': [],\n",
        "    'cum_VS_return_5_with_cost': [],\n",
        "    'cum_VLS_return_5_with_cost': [],\n",
        "    'cum_EL_return_5_without_cost': [],\n",
        "    'cum_ES_return_5_without_cost': [],\n",
        "    'cum_ELS_return_5_without_cost': [],\n",
        "    'cum_VL_return_5_without_cost': [],\n",
        "    'cum_VS_return_5_without_cost': [],\n",
        "    'cum_VLS_return_5_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 5\n",
        "cum_EL_return_5_with_cost = 0\n",
        "cum_ES_return_5_with_cost = 0\n",
        "cum_ELS_return_5_with_cost = 0\n",
        "cum_VL_return_5_with_cost = 0\n",
        "cum_VS_return_5_with_cost = 0\n",
        "cum_VLS_return_5_with_cost = 0\n",
        "\n",
        "cum_EL_return_5_without_cost = 0\n",
        "cum_ES_return_5_without_cost = 0\n",
        "cum_ELS_return_5_without_cost = 0\n",
        "cum_VL_return_5_without_cost = 0\n",
        "cum_VS_return_5_without_cost = 0\n",
        "cum_VLS_return_5_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 5 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 5 (or any other lag if needed)\n",
        "    returns = compute_returns(group, f'chronosboltsmall_{5}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 5\n",
        "    cum_EL_return_5_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_5_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_5_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_5_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_5_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_5_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_5_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_5_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_5_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_5_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_5_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_5_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 5 portfolios\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_EL_return_5_with_cost'].append(cum_EL_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_ES_return_5_with_cost'].append(cum_ES_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_ELS_return_5_with_cost'].append(cum_ELS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_VL_return_5_with_cost'].append(cum_VL_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_VS_return_5_with_cost'].append(cum_VS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_VLS_return_5_with_cost'].append(cum_VLS_return_5_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_EL_return_5_without_cost'].append(cum_EL_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_ES_return_5_without_cost'].append(cum_ES_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_ELS_return_5_without_cost'].append(cum_ELS_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_VL_return_5_without_cost'].append(cum_VL_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_VS_return_5_without_cost'].append(cum_VS_return_5_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall5['cum_VLS_return_5_without_cost'].append(cum_VLS_return_5_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 5\n",
        "cumulative_log_returns_chronosboltsmall_lag_5 = pd.DataFrame(cumulative_log_returns_by_date_chronosboltsmall5)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 5\n",
        "display(cumulative_log_returns_chronosboltsmall_lag_5.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosboltsmall_lag_5.to_csv(\"cumulative_log_chronosboltsmall_lag_5.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "Jdn9BVTZhy0N",
        "outputId": "04ad496f-c99e-4878-c01d-4d84fdebe059"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_5_with_cost', 'cum_ES_return_5_with_cost', 'cum_ELS_return_5_with_cost',\n",
        "    'cum_VL_return_5_with_cost', 'cum_VS_return_5_with_cost', 'cum_VLS_return_5_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosboltsmall5_c = cumulative_log_returns_chronosboltsmall_lag_5[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltsmall5_c)\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltsmall5_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosboltsmall5_c)\n",
        "\n",
        "#  same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_5_without_cost', 'cum_ES_return_5_without_cost', 'cum_ELS_return_5_without_cost',\n",
        "    'cum_VL_return_5_without_cost', 'cum_VS_return_5_without_cost', 'cum_VLS_return_5_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosboltsmall5_wc = cumulative_log_returns_chronosboltsmall_lag_5[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltsmall5_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltsmall5_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosboltsmall5_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosboltsmall5_c.to_csv('metrics_chronosboltsmall5_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosboltsmall5_wc.to_csv('metrics_chronosboltsmall5_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lea4OkdNgNEh"
      },
      "source": [
        "### Window Size 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "c7enevL-iL6q",
        "outputId": "d211bb6a-e657-4e55-81a1-bd6df111ee19"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosboltsmall` to predict excess returns\n",
        "def chronosboltsmall_21_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[21]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosboltsmall\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_small(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "        modified_crsp_test_lagged[f'chronosboltsmall_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosboltsmall model\n",
        "crsp_test_lagged = chronosboltsmall_21_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosboltsmall21  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_21_with_cost': [],\n",
        "    'cum_ES_return_21_with_cost': [],\n",
        "    'cum_ELS_return_21_with_cost': [],\n",
        "    'cum_VL_return_21_with_cost': [],\n",
        "    'cum_VS_return_21_with_cost': [],\n",
        "    'cum_VLS_return_21_with_cost': [],\n",
        "    'cum_EL_return_21_without_cost': [],\n",
        "    'cum_ES_return_21_without_cost': [],\n",
        "    'cum_ELS_return_21_without_cost': [],\n",
        "    'cum_VL_return_21_without_cost': [],\n",
        "    'cum_VS_return_21_without_cost': [],\n",
        "    'cum_VLS_return_21_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 21\n",
        "cum_EL_return_21_with_cost = 0\n",
        "cum_ES_return_21_with_cost = 0\n",
        "cum_ELS_return_21_with_cost = 0\n",
        "cum_VL_return_21_with_cost = 0\n",
        "cum_VS_return_21_with_cost = 0\n",
        "cum_VLS_return_21_with_cost = 0\n",
        "\n",
        "cum_EL_return_21_without_cost = 0\n",
        "cum_ES_return_21_without_cost = 0\n",
        "cum_ELS_return_21_without_cost = 0\n",
        "cum_VL_return_21_without_cost = 0\n",
        "cum_VS_return_21_without_cost = 0\n",
        "cum_VLS_return_21_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 21 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 21\n",
        "    returns = compute_returns(group, f'chronosboltsmall_{21}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 21\n",
        "    cum_EL_return_21_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_21_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_21_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_21_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_21_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_21_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_21_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_21_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_21_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_21_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_21_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_21_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 21 portfolios\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_EL_return_21_with_cost'].append(cum_EL_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_ES_return_21_with_cost'].append(cum_ES_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_ELS_return_21_with_cost'].append(cum_ELS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_VL_return_21_with_cost'].append(cum_VL_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_VS_return_21_with_cost'].append(cum_VS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_VLS_return_21_with_cost'].append(cum_VLS_return_21_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_EL_return_21_without_cost'].append(cum_EL_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_ES_return_21_without_cost'].append(cum_ES_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_ELS_return_21_without_cost'].append(cum_ELS_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_VL_return_21_without_cost'].append(cum_VL_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_VS_return_21_without_cost'].append(cum_VS_return_21_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall21['cum_VLS_return_21_without_cost'].append(cum_VLS_return_21_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 21\n",
        "cumulative_log_returns_chronosboltsmall_lag_21 = pd.DataFrame(cumulative_log_returns_by_date_chronosboltsmall21)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 21\n",
        "display(cumulative_log_returns_chronosboltsmall_lag_21.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosboltsmall_lag_21.to_csv(\"cumulative_log_chronosboltsmall_lag_21.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "NCnAvXHgirFh",
        "outputId": "58184e88-f482-4069-d670-ca34f2391e92"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_21_with_cost', 'cum_ES_return_21_with_cost', 'cum_ELS_return_21_with_cost',\n",
        "    'cum_VL_return_21_with_cost', 'cum_VS_return_21_with_cost', 'cum_VLS_return_21_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosboltsmall21_c = cumulative_log_returns_chronosboltsmall_lag_21[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltsmall21_c)\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltsmall21_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosboltsmall21_c)\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_21_without_cost', 'cum_ES_return_21_without_cost', 'cum_ELS_return_21_without_cost',\n",
        "    'cum_VL_return_21_without_cost', 'cum_VS_return_21_without_cost', 'cum_VLS_return_21_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosboltsmall21_wc = cumulative_log_returns_chronosboltsmall_lag_21[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltsmall21_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltsmall21_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosboltsmall21_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosboltsmall21_c.to_csv('metrics_chronosboltsmall21_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosboltsmall21_wc.to_csv('metrics_chronosboltsmall21_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58O779ohgOLI"
      },
      "source": [
        "### Window Size 252"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "63xeV8jdi-9v",
        "outputId": "5eabc495-ce3b-431b-cca4-938e141457d5"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosboltsmall` to predict excess returns\n",
        "def chronosboltsmall_252_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[252]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosboltsmall\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_small(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosboltsmall_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosboltsmall model\n",
        "crsp_test_lagged = chronosboltsmall_252_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "#  Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosboltsmall252  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_252_with_cost': [],\n",
        "    'cum_ES_return_252_with_cost': [],\n",
        "    'cum_ELS_return_252_with_cost': [],\n",
        "    'cum_VL_return_252_with_cost': [],\n",
        "    'cum_VS_return_252_with_cost': [],\n",
        "    'cum_VLS_return_252_with_cost': [],\n",
        "    'cum_EL_return_252_without_cost': [],\n",
        "    'cum_ES_return_252_without_cost': [],\n",
        "    'cum_ELS_return_252_without_cost': [],\n",
        "    'cum_VL_return_252_without_cost': [],\n",
        "    'cum_VS_return_252_without_cost': [],\n",
        "    'cum_VLS_return_252_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 252\n",
        "cum_EL_return_252_with_cost = 0\n",
        "cum_ES_return_252_with_cost = 0\n",
        "cum_ELS_return_252_with_cost = 0\n",
        "cum_VL_return_252_with_cost = 0\n",
        "cum_VS_return_252_with_cost = 0\n",
        "cum_VLS_return_252_with_cost = 0\n",
        "\n",
        "cum_EL_return_252_without_cost = 0\n",
        "cum_ES_return_252_without_cost = 0\n",
        "cum_ELS_return_252_without_cost = 0\n",
        "cum_VL_return_252_without_cost = 0\n",
        "cum_VS_return_252_without_cost = 0\n",
        "cum_VLS_return_252_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 252 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 252\n",
        "    returns = compute_returns(group, f'chronosboltsmall_{252}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 252\n",
        "    cum_EL_return_252_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_252_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_252_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_252_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_252_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_252_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_252_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_252_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_252_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_252_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_252_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_252_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 252 portfolios\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_EL_return_252_with_cost'].append(cum_EL_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_ES_return_252_with_cost'].append(cum_ES_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_ELS_return_252_with_cost'].append(cum_ELS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_VL_return_252_with_cost'].append(cum_VL_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_VS_return_252_with_cost'].append(cum_VS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_VLS_return_252_with_cost'].append(cum_VLS_return_252_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_EL_return_252_without_cost'].append(cum_EL_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_ES_return_252_without_cost'].append(cum_ES_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_ELS_return_252_without_cost'].append(cum_ELS_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_VL_return_252_without_cost'].append(cum_VL_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_VS_return_252_without_cost'].append(cum_VS_return_252_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall252['cum_VLS_return_252_without_cost'].append(cum_VLS_return_252_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 252\n",
        "cumulative_log_returns_chronosboltsmall_lag_252 = pd.DataFrame(cumulative_log_returns_by_date_chronosboltsmall252)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 252\n",
        "display(cumulative_log_returns_chronosboltsmall_lag_252.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosboltsmall_lag_252.to_csv(\"cumulative_log_chronosboltsmall_lag_252.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "icp1ilYMjBVE",
        "outputId": "e8678029-54d3-46df-d90f-7f494357864d"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_252_with_cost', 'cum_ES_return_252_with_cost', 'cum_ELS_return_252_with_cost',\n",
        "    'cum_VL_return_252_with_cost', 'cum_VS_return_252_with_cost', 'cum_VLS_return_252_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosboltsmall252_c = cumulative_log_returns_chronosboltsmall_lag_252[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltsmall252_c)\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)  # Using percentage-based cost for volatility\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost (using percentage-based cost for standard deviation)\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltsmall252_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosboltsmall252_c)\n",
        "\n",
        "\n",
        "# Now, the same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_252_without_cost', 'cum_ES_return_252_without_cost', 'cum_ELS_return_252_without_cost',\n",
        "    'cum_VL_return_252_without_cost', 'cum_VS_return_252_without_cost', 'cum_VLS_return_252_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosboltsmall252_wc = cumulative_log_returns_chronosboltsmall_lag_252[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltsmall252_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltsmall252_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosboltsmall252_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosboltsmall252_c.to_csv('metrics_chronosboltsmall252_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosboltsmall252_wc.to_csv('metrics_chronosboltsmall252_without_cost.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsYPcQU6gPFX"
      },
      "source": [
        "### Window Size 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "2lLoElASgLdr",
        "outputId": "ac5f81f1-6a51-4351-a8ef-b4c7ad22be19"
      },
      "outputs": [],
      "source": [
        "# Add transaction cost (10bps = 0.001)\n",
        "def calculate_transaction_cost(row):\n",
        "    return 0.001  # 10 bps for both small and large cap stocks\n",
        "\n",
        "crsp_test_lagged.loc[:, 'transaction_cost'] = crsp_test_lagged.apply(calculate_transaction_cost, axis=1)\n",
        "\n",
        "# Use the previously defined `chronosboltsmall` to predict excess returns\n",
        "def chronosboltsmall_512_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged, lags=[512]):\n",
        "    out_sample_start = \"2016-01-01\"\n",
        "    modified_crsp_test_lagged = crsp_test_lagged.copy()\n",
        "\n",
        "    for lag in lags:\n",
        "        # Pass each lag individually to chronosboltsmall\n",
        "        metrics_df, modified_crsp_test_lagged = run_forecast_chronos_bolt_small(crsp_train_lagged, modified_crsp_test_lagged, lag, out_sample_start)\n",
        "\n",
        "        pred_col = f'predicted_excess_returns_lag{lag}'\n",
        "        if pred_col not in modified_crsp_test_lagged.columns:\n",
        "             raise KeyError(f\"Column '{pred_col}' not found after running forecast.\")\n",
        "\n",
        "        modified_crsp_test_lagged[f'chronosboltsmall_{lag}_predicted_excess_returns'] = modified_crsp_test_lagged[pred_col].values\n",
        "\n",
        "    return modified_crsp_test_lagged\n",
        "\n",
        "# Get predicted excess returns using chronosboltsmall model\n",
        "crsp_test_lagged = chronosboltsmall_512_predicted_excess_returns(crsp_train_lagged, crsp_test_lagged)\n",
        "\n",
        "# Portfolio Construction (Top 10% Long, Bottom 10% Short)\n",
        "def compute_returns(group, predicted_col):\n",
        "    # Long position (Top 10% based on predicted returns)\n",
        "    top_positive = group.nlargest(int(0.1 * len(group)), predicted_col)\n",
        "    # Short position (Bottom 10% based on predicted returns)\n",
        "    top_negative = group.nsmallest(int(0.1 * len(group)), predicted_col)\n",
        "\n",
        "    # Equal-Weighted Long position return (Top 10%)\n",
        "    equal_long_log_return_with_cost = np.log1p(top_positive['adjusted_ret']).mean() - top_positive['transaction_cost'].mean()\n",
        "    equal_long_log_return_without_cost = np.log1p(top_positive['adjusted_ret']).mean()\n",
        "\n",
        "    # Equal-Weighted Short position return (Bottom 10%)\n",
        "    equal_short_log_return_with_cost = -np.log1p(top_negative['adjusted_ret']).mean() - top_negative['transaction_cost'].mean()\n",
        "    equal_short_log_return_without_cost = -np.log1p(top_negative['adjusted_ret']).mean()\n",
        "\n",
        "    # Value-Weighted Long position return (Top 10%) based on market cap\n",
        "    total_market_cap_positive = top_positive['market_cap_merged'].sum()\n",
        "    value_long_log_return_with_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive - top_positive['transaction_cost'].mean()\n",
        "    value_long_log_return_without_cost = (np.log1p(top_positive['adjusted_ret']) * top_positive['market_cap_merged']).sum() / total_market_cap_positive\n",
        "\n",
        "    # Value-Weighted Short position return (Bottom 10%) based on market cap\n",
        "    total_market_cap_negative = top_negative['market_cap_merged'].sum()\n",
        "    value_short_log_return_with_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative + top_negative['transaction_cost'].mean())\n",
        "    value_short_log_return_without_cost = -((np.log1p(top_negative['adjusted_ret']) * top_negative['market_cap_merged']).sum() / total_market_cap_negative)\n",
        "\n",
        "    # Combine Long and Short to get Long-Short return\n",
        "    equal_long_short_log_return_with_cost = equal_long_log_return_with_cost + equal_short_log_return_with_cost\n",
        "    equal_long_short_log_return_without_cost = equal_long_log_return_without_cost + equal_short_log_return_without_cost\n",
        "\n",
        "    value_long_short_log_return_with_cost = value_long_log_return_with_cost + value_short_log_return_with_cost\n",
        "    value_long_short_log_return_without_cost = value_long_log_return_without_cost + value_short_log_return_without_cost\n",
        "\n",
        "    return {\n",
        "        'equal_long_log_return_with_cost': equal_long_log_return_with_cost,\n",
        "        'equal_short_log_return_with_cost': equal_short_log_return_with_cost,\n",
        "        'equal_long_short_log_return_with_cost': equal_long_short_log_return_with_cost,\n",
        "        'equal_long_log_return_without_cost': equal_long_log_return_without_cost,\n",
        "        'equal_short_log_return_without_cost': equal_short_log_return_without_cost,\n",
        "        'equal_long_short_log_return_without_cost': equal_long_short_log_return_without_cost,\n",
        "        'value_long_log_return_with_cost': value_long_log_return_with_cost,\n",
        "        'value_short_log_return_with_cost': value_short_log_return_with_cost,\n",
        "        'value_long_short_log_return_with_cost': value_long_short_log_return_with_cost,\n",
        "        'value_long_log_return_without_cost': value_long_log_return_without_cost,\n",
        "        'value_short_log_return_without_cost': value_short_log_return_without_cost,\n",
        "        'value_long_short_log_return_without_cost': value_long_short_log_return_without_cost\n",
        "    }\n",
        "\n",
        "# Compute cumulative returns for each date with daily rebalancing\n",
        "cumulative_log_returns_by_date_chronosboltsmall512  = {\n",
        "    'date': [],\n",
        "    'cum_EL_return_512_with_cost': [],\n",
        "    'cum_ES_return_512_with_cost': [],\n",
        "    'cum_ELS_return_512_with_cost': [],\n",
        "    'cum_VL_return_512_with_cost': [],\n",
        "    'cum_VS_return_512_with_cost': [],\n",
        "    'cum_VLS_return_512_with_cost': [],\n",
        "    'cum_EL_return_512_without_cost': [],\n",
        "    'cum_ES_return_512_without_cost': [],\n",
        "    'cum_ELS_return_512_without_cost': [],\n",
        "    'cum_VL_return_512_without_cost': [],\n",
        "    'cum_VS_return_512_without_cost': [],\n",
        "    'cum_VLS_return_512_without_cost': []\n",
        "}\n",
        "\n",
        "# Initialize cumulative returns for lag 512\n",
        "cum_EL_return_512_with_cost = 0\n",
        "cum_ES_return_512_with_cost = 0\n",
        "cum_ELS_return_512_with_cost = 0\n",
        "cum_VL_return_512_with_cost = 0\n",
        "cum_VS_return_512_with_cost = 0\n",
        "cum_VLS_return_512_with_cost = 0\n",
        "\n",
        "cum_EL_return_512_without_cost = 0\n",
        "cum_ES_return_512_without_cost = 0\n",
        "cum_ELS_return_512_without_cost = 0\n",
        "cum_VL_return_512_without_cost = 0\n",
        "cum_VS_return_512_without_cost = 0\n",
        "cum_VLS_return_512_without_cost = 0\n",
        "\n",
        "# Iterate over each date to compute returns for lag 512 portfolios\n",
        "for date in crsp_test_lagged['date'].unique():\n",
        "    group = crsp_test_lagged[crsp_test_lagged['date'] == date]\n",
        "\n",
        "    # Compute returns for lag 512\n",
        "    returns = compute_returns(group, f'chronosboltsmall_{512}_predicted_excess_returns')\n",
        "\n",
        "    # Update cumulative returns with daily values for lag 512\n",
        "    cum_EL_return_512_with_cost += returns['equal_long_log_return_with_cost']\n",
        "    cum_ES_return_512_with_cost += returns['equal_short_log_return_with_cost']\n",
        "    cum_ELS_return_512_with_cost += returns['equal_long_short_log_return_with_cost']\n",
        "    cum_VL_return_512_with_cost += returns['value_long_log_return_with_cost']\n",
        "    cum_VS_return_512_with_cost += returns['value_short_log_return_with_cost']\n",
        "    cum_VLS_return_512_with_cost += returns['value_long_short_log_return_with_cost']\n",
        "\n",
        "    cum_EL_return_512_without_cost += returns['equal_long_log_return_without_cost']\n",
        "    cum_ES_return_512_without_cost += returns['equal_short_log_return_without_cost']\n",
        "    cum_ELS_return_512_without_cost += returns['equal_long_short_log_return_without_cost']\n",
        "    cum_VL_return_512_without_cost += returns['value_long_log_return_without_cost']\n",
        "    cum_VS_return_512_without_cost += returns['value_short_log_return_without_cost']\n",
        "    cum_VLS_return_512_without_cost += returns['value_long_short_log_return_without_cost']\n",
        "\n",
        "    # Append results for the day for lag 512 portfolios\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['date'].append(date)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_EL_return_512_with_cost'].append(cum_EL_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_ES_return_512_with_cost'].append(cum_ES_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_ELS_return_512_with_cost'].append(cum_ELS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_VL_return_512_with_cost'].append(cum_VL_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_VS_return_512_with_cost'].append(cum_VS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_VLS_return_512_with_cost'].append(cum_VLS_return_512_with_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_EL_return_512_without_cost'].append(cum_EL_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_ES_return_512_without_cost'].append(cum_ES_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_ELS_return_512_without_cost'].append(cum_ELS_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_VL_return_512_without_cost'].append(cum_VL_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_VS_return_512_without_cost'].append(cum_VS_return_512_without_cost)\n",
        "    cumulative_log_returns_by_date_chronosboltsmall512['cum_VLS_return_512_without_cost'].append(cum_VLS_return_512_without_cost)\n",
        "\n",
        "# Convert to DataFrame for lag 512\n",
        "cumulative_log_returns_chronosboltsmall_lag_512 = pd.DataFrame(cumulative_log_returns_by_date_chronosboltsmall512)\n",
        "\n",
        "# Display the cumulative returns DataFrame for lag 512\n",
        "display(cumulative_log_returns_chronosboltsmall_lag_512.head())\n",
        "\n",
        "# Saving the DataFrame as a CSV file\n",
        "cumulative_log_returns_chronosboltsmall_lag_512.to_csv(\"cumulative_log_chronosboltsmall_lag_512.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "iAnVuacOj0es",
        "outputId": "ede54a1d-2a0f-449b-be8e-2e1b85dd78a2"
      },
      "outputs": [],
      "source": [
        "# Cumulative returns\n",
        "def cumulative_return(daily_returns):\n",
        "    return np.prod(1 + daily_returns) - 1\n",
        "\n",
        "# Annualized returns\n",
        "def annualized_return(daily_returns, periods=252):\n",
        "    cumulative_return_value = np.prod(1 + daily_returns) - 1\n",
        "    return (1 + cumulative_return_value) ** (periods / len(daily_returns)) - 1\n",
        "\n",
        "# Sharpe ratio\n",
        "def sharpe_ratio(daily_returns, risk_free_rate=0.01, periods=252):\n",
        "    daily_rf = risk_free_rate / periods  # Assuming 252 trading days\n",
        "    excess_returns = daily_returns - daily_rf\n",
        "    return np.sqrt(periods) * excess_returns.mean() / excess_returns.std()\n",
        "\n",
        "# Calculate volatility (standard deviation) of daily returns\n",
        "def calculate_volatility(daily_returns, periods=252):\n",
        "    return np.std(daily_returns) * np.sqrt(periods)\n",
        "\n",
        "# Calculate maximum drawdown\n",
        "def maximum_drawdown(daily_returns):\n",
        "    cum_returns = np.cumprod(1 + daily_returns)\n",
        "    peak = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - peak) / peak\n",
        "    return np.min(drawdown)\n",
        "\n",
        "# Apply fixed transaction cost to the daily returns (for other metrics)\n",
        "def apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001):\n",
        "    # Subtract the transaction cost from each daily return\n",
        "    return daily_returns - transaction_cost\n",
        "\n",
        "# Apply percentage-based transaction cost to the daily returns (for volatility and standard deviation)\n",
        "def apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001):\n",
        "    # Apply transaction cost as a percentage of the return\n",
        "    return daily_returns * (1 - transaction_cost_percentage)\n",
        "\n",
        "# Prepare portfolio names (with transaction cost)\n",
        "portfolios_with_cost = [\n",
        "    'cum_EL_return_512_with_cost', 'cum_ES_return_512_with_cost', 'cum_ELS_return_512_with_cost',\n",
        "    'cum_VL_return_512_with_cost', 'cum_VS_return_512_with_cost', 'cum_VLS_return_512_with_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container\n",
        "metrics = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio with transaction cost\n",
        "for portfolio in portfolios_with_cost:\n",
        "    cumulative_returns_chronosboltsmall512_c = cumulative_log_returns_chronosboltsmall_lag_512[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltsmall512_c)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Apply fixed transaction cost for other metrics\n",
        "    daily_returns_after_cost_fixed = apply_transaction_cost_fixed(daily_returns, transaction_cost=0.001)\n",
        "\n",
        "    # Apply percentage-based transaction cost for volatility and standard deviation\n",
        "    daily_returns_after_cost_percentage = apply_transaction_cost_percentage(daily_returns, transaction_cost_percentage=0.001)\n",
        "\n",
        "    # Calculate cumulative returns after fixed transaction cost\n",
        "    cum_return_after_cost = cumulative_return(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns_after_cost_fixed)\n",
        "    sharpe = sharpe_ratio(daily_returns_after_cost_fixed)\n",
        "    vol = calculate_volatility(daily_returns_after_cost_percentage)\n",
        "    max_draw = maximum_drawdown(daily_returns_after_cost_fixed)\n",
        "\n",
        "    # Standard Deviation of daily returns after cost (using percentage-based cost for standard deviation)\n",
        "    std_dev = np.std(daily_returns_after_cost_percentage)\n",
        "\n",
        "    # Store results\n",
        "    metrics['Portfolio'].append(portfolio)\n",
        "    metrics['Annualized Return'].append(ann_return)\n",
        "    metrics['Sharpe Ratio'].append(sharpe)\n",
        "    metrics['Volatility'].append(vol)\n",
        "    metrics['Standard Deviation'].append(std_dev)\n",
        "    metrics['Max Drawdown'].append(max_draw)\n",
        "    metrics['Cumulative Return'].append(cum_return_after_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltsmall512_c = pd.DataFrame(metrics)\n",
        "display(metrics_chronosboltsmall512_c)\n",
        "\n",
        "# same calculations for portfolios without transaction cost\n",
        "portfolios_without_cost = [\n",
        "    'cum_EL_return_512_without_cost', 'cum_ES_return_512_without_cost', 'cum_ELS_return_512_without_cost',\n",
        "    'cum_VL_return_512_without_cost', 'cum_VS_return_512_without_cost', 'cum_VLS_return_512_without_cost',\n",
        "]\n",
        "\n",
        "# Initialize metrics container for portfolios without transaction cost\n",
        "metrics_wc = {\n",
        "    'Portfolio': [],\n",
        "    'Annualized Return': [],\n",
        "    'Sharpe Ratio': [],\n",
        "    'Volatility': [],\n",
        "    'Standard Deviation': [],\n",
        "    'Max Drawdown': [],\n",
        "    'Cumulative Return': []\n",
        "}\n",
        "\n",
        "# Calculate metrics for each portfolio without transaction cost\n",
        "for portfolio in portfolios_without_cost:\n",
        "    cumulative_returns_chronosboltsmall512_wc = cumulative_log_returns_chronosboltsmall_lag_512[portfolio].values\n",
        "\n",
        "    # Calculate daily returns from cumulative returns\n",
        "    daily_returns = np.diff(cumulative_returns_chronosboltsmall512_wc)  # Compute daily returns from cumulative log returns\n",
        "\n",
        "    # Calculate cumulative returns without transaction cost\n",
        "    cum_return_without_cost = cumulative_return(daily_returns)\n",
        "\n",
        "    # Metrics calculations\n",
        "    ann_return = annualized_return(daily_returns)\n",
        "    sharpe = sharpe_ratio(daily_returns)\n",
        "    vol = calculate_volatility(daily_returns)\n",
        "    max_draw = maximum_drawdown(daily_returns)\n",
        "\n",
        "    # Standard Deviation of daily returns without cost\n",
        "    std_dev = np.std(daily_returns)\n",
        "\n",
        "    # Store results\n",
        "    metrics_wc['Portfolio'].append(portfolio)\n",
        "    metrics_wc['Annualized Return'].append(ann_return)\n",
        "    metrics_wc['Sharpe Ratio'].append(sharpe)\n",
        "    metrics_wc['Volatility'].append(vol)\n",
        "    metrics_wc['Standard Deviation'].append(std_dev)\n",
        "    metrics_wc['Max Drawdown'].append(max_draw)\n",
        "    metrics_wc['Cumulative Return'].append(cum_return_without_cost)\n",
        "\n",
        "# Convert the results into a DataFrame for analysis\n",
        "metrics_chronosboltsmall512_wc = pd.DataFrame(metrics_wc)\n",
        "display(metrics_chronosboltsmall512_wc)\n",
        "\n",
        "# Save the portfolio metrics with transaction costs\n",
        "metrics_chronosboltsmall512_c.to_csv('metrics_chronosboltsmall512_with_cost.csv', index=False)\n",
        "\n",
        "# Save the portfolio metrics without transaction costs\n",
        "metrics_chronosboltsmall512_wc.to_csv('metrics_chronosboltsmall512_without_cost.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Gl3cjoU9BjrX",
        "5ph1EzpeJJiV",
        "_a4pJND_8IPp",
        "o5uP2xDdQpVt",
        "MAJ2GvzHdNJU",
        "VZ0jJeduqKbK",
        "ZQl0wFWLs3Mk",
        "GwOhimF3s6R9",
        "mH1JIOxyt8cg",
        "Bm2DIN1cvBrA",
        "OKrmZBPzBKyX",
        "CWUYyWxUM2Iq",
        "XD73ASylM6q7",
        "UdsHzFg_g3i0",
        "v9VKkKoCpHI1",
        "63CroKZBumLm",
        "sns-5c9Z4N89",
        "8tm133B471_K",
        "Wibh-dQ3pfks",
        "ln9Zmcr6puDo",
        "152IP6jdIkCM",
        "RQdy21ugJIVv",
        "MwrrRQt4P5_i",
        "pIGfFvT6RRaI",
        "S4m6mRo5tmCI",
        "4Zx_-UrJgI84",
        "6NvCy5zYgL3F",
        "lea4OkdNgNEh",
        "58O779ohgOLI",
        "rsYPcQU6gPFX",
        "_4W9V1rOscdX"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08b0c8fd83ab42899a0111fd67d0bc94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0957cc0a234b4d5ba085c016a5d6f15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d11275d2aa0471ea27b8f5df6c7bedc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b7fdf465c484430a7ec57039e70374d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b6251b1fa7646989886370120bae09b",
            "placeholder": "​",
            "style": "IPY_MODEL_3b28cc4384ee4a2e8393b7fb8b65972b",
            "value": " 33.6M/33.6M [00:01&lt;00:00, 22.9MB/s]"
          }
        },
        "28fc4f83515d4256862128cc9976e17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8436d83ebc3f4821b82b9b6555a10f63",
              "IPY_MODEL_bc8c2b8253cd45a28e49ad66b60fdd77",
              "IPY_MODEL_82ad82b8ac134452a65033ad758a53ed"
            ],
            "layout": "IPY_MODEL_eb570852d59d49c5b639350a2bf5d2cb"
          }
        },
        "2b6251b1fa7646989886370120bae09b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33d314491ffa43239bc9c9dfa47e3419": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382cd0d3d5944c6495cb5fba0bb3dbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d314491ffa43239bc9c9dfa47e3419",
            "max": 33588440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9976eb7c8a64fc6b70822ddf96d83a0",
            "value": 33588440
          }
        },
        "3b28cc4384ee4a2e8393b7fb8b65972b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f638a8821564890b3a7061d467b4d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6a0000be7a4589a8ee36d5c8f88ff3",
            "placeholder": "​",
            "style": "IPY_MODEL_e4a0b96acde14442a580274378f6fcb6",
            "value": "generation_config.json: 100%"
          }
        },
        "416b8185f9c848e699c0466a05a2926b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "494fc22b14dc4282a17cbd481e9ecdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bcffd06f5f144969ad0f8ace650419c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5248ec40691f46a88a8d0267db51435d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675ef567a07e498c9837bc4c5a92dc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f638a8821564890b3a7061d467b4d82",
              "IPY_MODEL_789c14c4ca4546d182e3e8a0ee2d9373",
              "IPY_MODEL_94855e0e08b94d448dd174238f1c8b94"
            ],
            "layout": "IPY_MODEL_d435e10d772f4f50a8b405f1999c4cad"
          }
        },
        "789c14c4ca4546d182e3e8a0ee2d9373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ced2f3a3b306422f856b18b6ece2abf9",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89e265d4cd3f43ba9f476bc73063fefd",
            "value": 142
          }
        },
        "82ad82b8ac134452a65033ad758a53ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5248ec40691f46a88a8d0267db51435d",
            "placeholder": "​",
            "style": "IPY_MODEL_0957cc0a234b4d5ba085c016a5d6f15a",
            "value": " 1.14k/? [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "8436d83ebc3f4821b82b9b6555a10f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92ce63902444f2f816c3efa8a7ac2af",
            "placeholder": "​",
            "style": "IPY_MODEL_4bcffd06f5f144969ad0f8ace650419c",
            "value": "config.json: "
          }
        },
        "89e265d4cd3f43ba9f476bc73063fefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b053fceab50414ab645746dd59aa09e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "94855e0e08b94d448dd174238f1c8b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d11275d2aa0471ea27b8f5df6c7bedc",
            "placeholder": "​",
            "style": "IPY_MODEL_494fc22b14dc4282a17cbd481e9ecdaf",
            "value": " 142/142 [00:00&lt;00:00, 2.12kB/s]"
          }
        },
        "98f12bc2038b49feacee02bdd6af84be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08b0c8fd83ab42899a0111fd67d0bc94",
            "placeholder": "​",
            "style": "IPY_MODEL_fa0c1a027730422d961591044efb3ab9",
            "value": "model.safetensors: 100%"
          }
        },
        "bc6a0000be7a4589a8ee36d5c8f88ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8c2b8253cd45a28e49ad66b60fdd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b053fceab50414ab645746dd59aa09e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_416b8185f9c848e699c0466a05a2926b",
            "value": 1
          }
        },
        "c9976eb7c8a64fc6b70822ddf96d83a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ced2f3a3b306422f856b18b6ece2abf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2778d3c30ca4bb98a0997c8d376be20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32e084f3b664c788502d970fb446e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98f12bc2038b49feacee02bdd6af84be",
              "IPY_MODEL_382cd0d3d5944c6495cb5fba0bb3dbee",
              "IPY_MODEL_1b7fdf465c484430a7ec57039e70374d"
            ],
            "layout": "IPY_MODEL_d2778d3c30ca4bb98a0997c8d376be20"
          }
        },
        "d435e10d772f4f50a8b405f1999c4cad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92ce63902444f2f816c3efa8a7ac2af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a0b96acde14442a580274378f6fcb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb570852d59d49c5b639350a2bf5d2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0c1a027730422d961591044efb3ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
